{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiment_adversarial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5a04a6325134fe5aef753742d75c1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bdd2237ddb9f4ceda4c50b27ded09d14",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5705acb32e9848a4b1c8eef76816bd59",
              "IPY_MODEL_93a68ad1fc494a84beae196e14ef1054"
            ]
          }
        },
        "bdd2237ddb9f4ceda4c50b27ded09d14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5705acb32e9848a4b1c8eef76816bd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b6bdedcbe12a4088891155d51c3b1235",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0993d03e7f0448818d9c37c6470eb086"
          }
        },
        "93a68ad1fc494a84beae196e14ef1054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1fc2db50333b465388ea524433682519",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 522kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_455a4c74464d488b8d7813bdb8b8f5dc"
          }
        },
        "b6bdedcbe12a4088891155d51c3b1235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0993d03e7f0448818d9c37c6470eb086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fc2db50333b465388ea524433682519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "455a4c74464d488b8d7813bdb8b8f5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3108613aea4c45c38965424e68a96a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_330847624e474cb9962b808203bbeed0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_202de836d0d643bd8b1275c4d037393e",
              "IPY_MODEL_2e3d2c384a2e4ce7b4a16c28289990a4"
            ]
          }
        },
        "330847624e474cb9962b808203bbeed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "202de836d0d643bd8b1275c4d037393e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b12dc1d51f248a3ba902935f00c69b6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74203fe573544d9fa58dc68a7da913a1"
          }
        },
        "2e3d2c384a2e4ce7b4a16c28289990a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7984dbf38f3145e6bc9b634ba8c05bbf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 976kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75063b2818bf4587aaacff99e3494a27"
          }
        },
        "2b12dc1d51f248a3ba902935f00c69b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74203fe573544d9fa58dc68a7da913a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7984dbf38f3145e6bc9b634ba8c05bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75063b2818bf4587aaacff99e3494a27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3b5cd18c45b42fbad341daa8dcfc4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1259f3359db242b093732b87f0dfb689",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8ba82e8b5f44df5a27bd3314ccd60c1",
              "IPY_MODEL_291c733326eb46f39db12dbcafe052dc"
            ]
          }
        },
        "1259f3359db242b093732b87f0dfb689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8ba82e8b5f44df5a27bd3314ccd60c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_41736ffb67954ec99c6f62d22554f051",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26b3ab4ae8b644a5b36401e1047b6912"
          }
        },
        "291c733326eb46f39db12dbcafe052dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40b3d7feceac4ced9661ee83b45dc0f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 3.00kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6de1917a44f14c03aecc8210c711e44e"
          }
        },
        "41736ffb67954ec99c6f62d22554f051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26b3ab4ae8b644a5b36401e1047b6912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40b3d7feceac4ced9661ee83b45dc0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6de1917a44f14c03aecc8210c711e44e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d95b29d7ee24ae48d754dce0ac942e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8a0f01fcbacf4ddaa0e94368d36451c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8cfd02d6040143f79b35785b6a40b17e",
              "IPY_MODEL_ef971695a25e41f08525d9cd80b6e542"
            ]
          }
        },
        "8a0f01fcbacf4ddaa0e94368d36451c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cfd02d6040143f79b35785b6a40b17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2667bc2a72a46c3ae4eab466aa11146",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32cfabd33b274864b006ce5714eb6a38"
          }
        },
        "ef971695a25e41f08525d9cd80b6e542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_04c7ae65af9c48bdb8a0fb4ef127975c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:46&lt;00:00, 10.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc1d32ccc2b34dc49a77c8dee66da419"
          }
        },
        "d2667bc2a72a46c3ae4eab466aa11146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32cfabd33b274864b006ce5714eb6a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04c7ae65af9c48bdb8a0fb4ef127975c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc1d32ccc2b34dc49a77c8dee66da419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMqUFyziS_tQ",
        "colab_type": "text"
      },
      "source": [
        "**Installations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "135PswSfSQYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "6811b638-3c82-4d31-87b2-168762a2405e"
      },
      "source": [
        "  !pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 4.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 6.3MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 6.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 6.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 7.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=a74456e68df96ed83c1e028b08d7cd426e6393106002e266ec9cbf80cc25c720\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm6kmrSxS1Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIJYSJXyTZ-8",
        "colab_type": "text"
      },
      "source": [
        "**Downloading CoLA data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctpdr9tiS1i6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d3b31828-e68b-4e30-f7a1-184940ab4340"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=3294139f80f46b5ab2ec1e23b0c4b4584317304f7cb36f27a0428bca6859c1ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yrzqVSrS49w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf3fa408-cc21-4e5d-9b57-64872970d787"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-5aFGES7K4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "d7a343a8-a7c5-4e21-df43-fd282a7f02da"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vww0Zu1UkL3T",
        "colab_type": "text"
      },
      "source": [
        "**extract and tokenize data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiRnG8PHkLAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "sentences=[]\n",
        "labels=[]\n",
        "with open(\"./cola_public/raw/in_domain_train.tsv\") as tsvfile:\n",
        "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
        "    for line in tsvreader:\n",
        "        sentences += [line[3]]\n",
        "        labels += [int(line[1])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIxZpDwwku0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "d5a04a6325134fe5aef753742d75c1ce",
            "bdd2237ddb9f4ceda4c50b27ded09d14",
            "5705acb32e9848a4b1c8eef76816bd59",
            "93a68ad1fc494a84beae196e14ef1054",
            "b6bdedcbe12a4088891155d51c3b1235",
            "0993d03e7f0448818d9c37c6470eb086",
            "1fc2db50333b465388ea524433682519",
            "455a4c74464d488b8d7813bdb8b8f5dc",
            "3108613aea4c45c38965424e68a96a48",
            "330847624e474cb9962b808203bbeed0",
            "202de836d0d643bd8b1275c4d037393e",
            "2e3d2c384a2e4ce7b4a16c28289990a4",
            "2b12dc1d51f248a3ba902935f00c69b6",
            "74203fe573544d9fa58dc68a7da913a1",
            "7984dbf38f3145e6bc9b634ba8c05bbf",
            "75063b2818bf4587aaacff99e3494a27"
          ]
        },
        "outputId": "eaaa7ec0-9f19-43f1-89cc-eb5d28288d95"
      },
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base') \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5a04a6325134fe5aef753742d75c1ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3108613aea4c45c38965424e68a96a48",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xlptfs4kr4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "be0634ad-450e-43ae-d19e-6ea1594decb8"
      },
      "source": [
        "# ici juste un tour pour voir quelle est la taille max . on visera un peu pls haut par sécurité.\n",
        "\n",
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZjuY-eSkxhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "c570f70e-f053-41c1-b3e7-2e2b2b4510b0"
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "for sent in sentences:\n",
        "  encoded_dict = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "  # Add the encoded sentence to the list.    \n",
        "  input_ids.append(encoded_dict)\n",
        "    \n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([    0,  1541,   964,   351,    75,   907,    42,  1966,     6,   905,\n",
            "         1937,     5,   220,    65,    52, 15393,     4,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBAKtB2WlCyE",
        "colab_type": "text"
      },
      "source": [
        "**prepare training and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8h1pF8DlF_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91gw-CHSlJp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snao8QB4lNyq",
        "colab_type": "text"
      },
      "source": [
        "**create model to be finetuned**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUvSSGWqlLqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f3b5cd18c45b42fbad341daa8dcfc4a3",
            "1259f3359db242b093732b87f0dfb689",
            "f8ba82e8b5f44df5a27bd3314ccd60c1",
            "291c733326eb46f39db12dbcafe052dc",
            "41736ffb67954ec99c6f62d22554f051",
            "26b3ab4ae8b644a5b36401e1047b6912",
            "40b3d7feceac4ced9661ee83b45dc0f9",
            "6de1917a44f14c03aecc8210c711e44e",
            "0d95b29d7ee24ae48d754dce0ac942e3",
            "8a0f01fcbacf4ddaa0e94368d36451c3",
            "8cfd02d6040143f79b35785b6a40b17e",
            "ef971695a25e41f08525d9cd80b6e542",
            "d2667bc2a72a46c3ae4eab466aa11146",
            "32cfabd33b274864b006ce5714eb6a38",
            "04c7ae65af9c48bdb8a0fb4ef127975c",
            "fc1d32ccc2b34dc49a77c8dee66da419"
          ]
        },
        "outputId": "4e180137-e3ee-48f1-d578-11aa009b7bbb"
      },
      "source": [
        "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3b5cd18c45b42fbad341daa8dcfc4a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d95b29d7ee24ae48d754dce0ac942e3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px8Ow-o8lfDj",
        "colab_type": "text"
      },
      "source": [
        "**prepare finetuning training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODfEZF5elhhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# see https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "\n",
        "from transformers import AdamW\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v_fiLYylj5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp63EsBelle2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g_KM56nlnEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gLgOukEloyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ec2a60bb-e246-4b8b-fee0-73f9b299866d"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79BRC_p6luzn",
        "colab_type": "text"
      },
      "source": [
        "**train.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeQxc__clrTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e38c9ade-6c5d-4ab5-a936-d3add1ae5d11"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:28.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:56.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:24.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:51.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:19.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:47.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:02:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.48\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:28.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:56.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:24.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:52.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:21.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:49.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:02:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.40\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:28.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:56.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:24.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:52.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:21.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:49.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 0:02:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.47\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:28.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:56.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:24.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:53.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:21.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:49.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:02:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.49\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:11:39 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrY6DDZ5u9Nr",
        "colab_type": "text"
      },
      "source": [
        "# Gradient sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwKvrKdTs-C5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers.modeling_utils import create_position_ids_from_input_ids\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz8lcM4Ig9St",
        "colab_type": "text"
      },
      "source": [
        "**experiments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTZP93uPlmmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCfl3KsVg-pX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = input_ids[0].unsqueeze(0).to(device)\n",
        "y=labels[0].unsqueeze(0).to(device)  \n",
        "ind=2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZFUuDbphXtt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "fa632a15-8261-4657-9aba-f5b0df073281"
      },
      "source": [
        "tokenizer.decode(x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<s> Our friends won't buy this analysis, let alone the next one we propose.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDuxH06Akcay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_matrix = model.roberta.embeddings.word_embeddings.weight\n",
        "normed_emb_matrix=F.normalize(emb_matrix, p=2, dim=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKWq4UZrmi1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neighboors(embedd,numb):\n",
        "  normed_emb_word=F.normalize(embedd, p=2, dim=0) \n",
        "  cosine_similarity = torch.matmul(normed_emb_word, torch.transpose(normed_emb_matrix,0,1))\n",
        "  calc, closest_words = torch.topk(cosine_similarity,numb,dim=0)\n",
        "  print(tokenizer.decode(closest_words))\n",
        "  return closest_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ssCbDtgjYDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace(x,ind,word):\n",
        "  x[0][ind]=word\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubDauiCrsxD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "77a813b4-bb4d-4a61-8073-11b1959af8a2"
      },
      "source": [
        "model(replace(x,ind,int(closest_words[0])),labels=y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor([[-2.4664,  2.1496]], device='cuda:0', grad_fn=<AddmmBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQY2ormwuBz3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ed4ffff3-c03b-49ae-f3c7-d1efa86fd9f1"
      },
      "source": [
        "model(replace(x,ind,73),labels=y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.0773, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor([[ 0.1691, -0.4919]], device='cuda:0', grad_fn=<AddmmBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbB3yYvHuolz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac95d81b-bbf9-4e12-e2e1-cfb8d8979eec"
      },
      "source": [
        "tokenizer.decode(torch.Tensor([73]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBLPnXyizgdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def descent(x,y,ind):\n",
        "  emb=predict1(x)\n",
        "  att=PGDAttack(predict2, loss_fn=None, eps=0.3, nb_iter=100,\n",
        "            eps_iter=0.005, rand_init=True, clip_min=-1., clip_max=1.,\n",
        "            ord=np.inf, l1_sparsity=None, targeted=False)\n",
        "  rval, norm_memory, loss_memory =att.perturb(x,emb,ind,y)\n",
        "  return rval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgGryEDDLPBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af68c440-4634-49ed-e6b2-6cc9cab9fb37"
      },
      "source": [
        "embedd=descent(x,y,ind)[0][ind]\n",
        "closest_words0=neighboors(embedd,10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " friends friend buddies acquaintances friendships teammatesFriends girlfriends Friendsfriends\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37BMX_ogsVg_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19c5ea9d-705d-4bea-a460-688149ec8abb"
      },
      "source": [
        "embedd2=list(model.roberta.embeddings.children())[:1][0](x)[0][ind] #batch:0, word:ind\n",
        "closest_words=neighboors(embedd2,10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " friends friendFriends buddies Friendsfriends pals friendships girlfriends acquaintances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfsdXaPrpm8f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9d2bc1a8-5314-409c-caa6-bb913a859c2a"
      },
      "source": [
        "closest_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  964,  1441, 36042, 30489,  7837, 33601, 20633, 22942, 34333, 37069],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8h19VMa-leT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cand=torch.empty((10,len(embedd2)))\n",
        "for t in range(10):\n",
        "  cand[t]=list(model.roberta.embeddings.children())[:1][0](closest_words[t].unsqueeze(0))\n",
        "cand=cand.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdSE53hUC7zN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "7c65b3c4-1535-40c9-c0d5-c12a0790584a"
      },
      "source": [
        "cand"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0051, -0.2012, -0.0584,  ..., -0.0299,  0.0074,  0.1229],\n",
              "        [ 0.0266, -0.1693, -0.0703,  ...,  0.0503, -0.0040,  0.1850],\n",
              "        [ 0.1099, -0.0235, -0.0031,  ..., -0.1241, -0.0738,  0.1472],\n",
              "        ...,\n",
              "        [ 0.1863, -0.0026,  0.0776,  ..., -0.1752,  0.1869,  0.1562],\n",
              "        [ 0.0842, -0.1774,  0.0298,  ...,  0.0288,  0.1118,  0.1221],\n",
              "        [ 0.0991, -0.2500, -0.0022,  ..., -0.0839,  0.0688,  0.2494]],\n",
              "       device='cuda:0', grad_fn=<CopyBackwards>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIHeSUVpmU-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb=predict1(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHl-fDLBzkL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a, b, c = emb.size()\n",
        "d=cand.size()[0]\n",
        "embdelt = torch.zeros(d,a,b,c).to(device)\n",
        "for jj in range(d):\n",
        "  embdelt[jj][0][ind]=cand[jj]\n",
        "embdelt=embdelt.permute(1,2,3,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsdvnEbQmW2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embdelt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVN9G6kwA2TE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "att=PGDAttack(predict2, loss_fn=None, eps=0.3, nb_iter=100,\n",
        "            eps_iter=0.0001, rand_init=True, clip_min=-1., clip_max=1.,\n",
        "            ord=np.inf, l1_sparsity=None, targeted=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv-z0ukBBMxx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "e92be4b8-2dd9-41b2-cdfa-ceb6d521a76a"
      },
      "source": [
        "rval, norm_memory, loss_memory =att.perturb_cand(x,emb,cand,embdelt,ind,y)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-222-1715ef9e901a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_memory\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturb_cand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membdelt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-220-f96499745149>\u001b[0m in \u001b[0;36mperturb_cand\u001b[0;34m(self, x, emb, cand, embdelt, ind, y)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mclip_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0ml1_sparsity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_sparsity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-215-b5d12a3dfaa5>\u001b[0m in \u001b[0;36mperturb_iterative_cand\u001b[0;34m(xvar, embvar, embdelt, indvar, yvar, predict, nb_iter, eps, eps_iter, loss_fn, delta_init, minimize, ord, clip_min, clip_max, l1_sparsity)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ok\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejT4UNCOJsE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0bf57aff-e3f9-48b8-87ff-21dcdd130ffa"
      },
      "source": [
        "torch.randn(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5097, -0.6720,  1.7055,  1.9970])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoLotHxVpf06",
        "colab_type": "text"
      },
      "source": [
        "**gradient descent on one input WITHOUT advertorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFtIAteHsL1Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f30d7cc-f316-411e-ce2b-8aa7e5e961d8"
      },
      "source": [
        "torch.rand((10)).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE4Lui7pvqyW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64f9c0d7-3e1e-4649-d979-24cb5d58bf6d"
      },
      "source": [
        "emb.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkI1XvwoP2SU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0c226a9-8a4d-4dbe-de83-1b8ab46bd304"
      },
      "source": [
        "#batch\n",
        "x = input_ids[0].unsqueeze(0).to(device)\n",
        "y = labels[0].unsqueeze(0).to(device)\n",
        "\n",
        "#descent param\n",
        "lr = 1e-4\n",
        "n_epochs = 100\n",
        "\n",
        "#contain results\n",
        "norm_memory=np.zeros((n_epochs,))\n",
        "loss_memory=np.zeros((n_epochs,))\n",
        "\n",
        "add=torch.rand((10),requires_grad=True).to(device)\n",
        "add.retain_grad()\n",
        "\n",
        "emb=predict1(x)\n",
        "for t in range(emb.size()[2]):\n",
        "  emb[0][ind][t]=0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  out=predict2(x,emb+torch.matmul(embdelt,add))  \n",
        "\n",
        "  criterion=torch.nn.CrossEntropyLoss()\n",
        "  loss=criterion(out,y) \n",
        "  outgrad=loss.backward(retain_graph=True)\n",
        "\n",
        "  print(\"epoch %s: norm of add is %f and loss is %e\" %(epoch,torch.norm(add,2),loss))\n",
        "  norm_memory[epoch]=torch.norm(torch.matmul(embdelt,add),2)\n",
        "  loss_memory[epoch]= loss\n",
        "\n",
        "  with torch.no_grad():\n",
        "        add += lr * torch.sign(add.grad)\n",
        "      \n",
        "  add.grad.zero_()\n",
        "\n",
        "emb_final=emb+torch.matmul(embdelt,add)\n",
        "  \n",
        "\n",
        "print(\"descent\")\n",
        "plt.plot(norm_memory)\n",
        "plt.suptitle('evolution of the norm of adversarial addition')\n",
        "plt.axis()\n",
        "plt.show()\n",
        "plt.plot(loss_memory)\n",
        "plt.suptitle('evolution of the losses')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0: norm of add is 1.655964 and loss is 1.174784e-02\n",
            "epoch 1: norm of add is 1.656236 and loss is 1.175308e-02\n",
            "epoch 2: norm of add is 1.656507 and loss is 1.175833e-02\n",
            "epoch 3: norm of add is 1.656778 and loss is 1.176357e-02\n",
            "epoch 4: norm of add is 1.657050 and loss is 1.176882e-02\n",
            "epoch 5: norm of add is 1.657321 and loss is 1.177406e-02\n",
            "epoch 6: norm of add is 1.657592 and loss is 1.177931e-02\n",
            "epoch 7: norm of add is 1.657863 and loss is 1.178455e-02\n",
            "epoch 8: norm of add is 1.658135 and loss is 1.178980e-02\n",
            "epoch 9: norm of add is 1.658406 and loss is 1.179504e-02\n",
            "epoch 10: norm of add is 1.658678 and loss is 1.180029e-02\n",
            "epoch 11: norm of add is 1.658949 and loss is 1.180577e-02\n",
            "epoch 12: norm of add is 1.659220 and loss is 1.181102e-02\n",
            "epoch 13: norm of add is 1.659492 and loss is 1.181626e-02\n",
            "epoch 14: norm of add is 1.659763 and loss is 1.182175e-02\n",
            "epoch 15: norm of add is 1.660035 and loss is 1.182699e-02\n",
            "epoch 16: norm of add is 1.660306 and loss is 1.183224e-02\n",
            "epoch 17: norm of add is 1.660578 and loss is 1.183772e-02\n",
            "epoch 18: norm of add is 1.660849 and loss is 1.184297e-02\n",
            "epoch 19: norm of add is 1.661121 and loss is 1.184821e-02\n",
            "epoch 20: norm of add is 1.661392 and loss is 1.185369e-02\n",
            "epoch 21: norm of add is 1.661664 and loss is 1.185894e-02\n",
            "epoch 22: norm of add is 1.661935 and loss is 1.186442e-02\n",
            "epoch 23: norm of add is 1.662207 and loss is 1.186991e-02\n",
            "epoch 24: norm of add is 1.662479 and loss is 1.187539e-02\n",
            "epoch 25: norm of add is 1.662750 and loss is 1.188064e-02\n",
            "epoch 26: norm of add is 1.663022 and loss is 1.188612e-02\n",
            "epoch 27: norm of add is 1.663293 and loss is 1.189160e-02\n",
            "epoch 28: norm of add is 1.663565 and loss is 1.189685e-02\n",
            "epoch 29: norm of add is 1.663837 and loss is 1.190257e-02\n",
            "epoch 30: norm of add is 1.664109 and loss is 1.190782e-02\n",
            "epoch 31: norm of add is 1.664380 and loss is 1.191354e-02\n",
            "epoch 32: norm of add is 1.664652 and loss is 1.191878e-02\n",
            "epoch 33: norm of add is 1.664924 and loss is 1.192427e-02\n",
            "epoch 34: norm of add is 1.665195 and loss is 1.192975e-02\n",
            "epoch 35: norm of add is 1.665467 and loss is 1.193547e-02\n",
            "epoch 36: norm of add is 1.665739 and loss is 1.194096e-02\n",
            "epoch 37: norm of add is 1.666011 and loss is 1.194644e-02\n",
            "epoch 38: norm of add is 1.666283 and loss is 1.195192e-02\n",
            "epoch 39: norm of add is 1.666555 and loss is 1.195741e-02\n",
            "epoch 40: norm of add is 1.666826 and loss is 1.196313e-02\n",
            "epoch 41: norm of add is 1.667098 and loss is 1.196837e-02\n",
            "epoch 42: norm of add is 1.667370 and loss is 1.197410e-02\n",
            "epoch 43: norm of add is 1.667642 and loss is 1.197958e-02\n",
            "epoch 44: norm of add is 1.667914 and loss is 1.198530e-02\n",
            "epoch 45: norm of add is 1.668186 and loss is 1.199079e-02\n",
            "epoch 46: norm of add is 1.668458 and loss is 1.199651e-02\n",
            "epoch 47: norm of add is 1.668730 and loss is 1.200199e-02\n",
            "epoch 48: norm of add is 1.669002 and loss is 1.200771e-02\n",
            "epoch 49: norm of add is 1.669274 and loss is 1.201320e-02\n",
            "epoch 50: norm of add is 1.669546 and loss is 1.201892e-02\n",
            "epoch 51: norm of add is 1.669818 and loss is 1.202464e-02\n",
            "epoch 52: norm of add is 1.670090 and loss is 1.203012e-02\n",
            "epoch 53: norm of add is 1.670362 and loss is 1.203585e-02\n",
            "epoch 54: norm of add is 1.670634 and loss is 1.204157e-02\n",
            "epoch 55: norm of add is 1.670906 and loss is 1.204705e-02\n",
            "epoch 56: norm of add is 1.671178 and loss is 1.205277e-02\n",
            "epoch 57: norm of add is 1.671450 and loss is 1.205850e-02\n",
            "epoch 58: norm of add is 1.671723 and loss is 1.206422e-02\n",
            "epoch 59: norm of add is 1.671995 and loss is 1.206994e-02\n",
            "epoch 60: norm of add is 1.672267 and loss is 1.207566e-02\n",
            "epoch 61: norm of add is 1.672539 and loss is 1.208138e-02\n",
            "epoch 62: norm of add is 1.672811 and loss is 1.208711e-02\n",
            "epoch 63: norm of add is 1.673083 and loss is 1.209283e-02\n",
            "epoch 64: norm of add is 1.673356 and loss is 1.209855e-02\n",
            "epoch 65: norm of add is 1.673628 and loss is 1.210427e-02\n",
            "epoch 66: norm of add is 1.673900 and loss is 1.210999e-02\n",
            "epoch 67: norm of add is 1.674172 and loss is 1.211572e-02\n",
            "epoch 68: norm of add is 1.674445 and loss is 1.212168e-02\n",
            "epoch 69: norm of add is 1.674717 and loss is 1.212740e-02\n",
            "epoch 70: norm of add is 1.674989 and loss is 1.213312e-02\n",
            "epoch 71: norm of add is 1.675262 and loss is 1.213884e-02\n",
            "epoch 72: norm of add is 1.675534 and loss is 1.214480e-02\n",
            "epoch 73: norm of add is 1.675806 and loss is 1.215053e-02\n",
            "epoch 74: norm of add is 1.676079 and loss is 1.215625e-02\n",
            "epoch 75: norm of add is 1.676351 and loss is 1.216221e-02\n",
            "epoch 76: norm of add is 1.676624 and loss is 1.216817e-02\n",
            "epoch 77: norm of add is 1.676896 and loss is 1.217389e-02\n",
            "epoch 78: norm of add is 1.677168 and loss is 1.217985e-02\n",
            "epoch 79: norm of add is 1.677441 and loss is 1.218557e-02\n",
            "epoch 80: norm of add is 1.677713 and loss is 1.219153e-02\n",
            "epoch 81: norm of add is 1.677986 and loss is 1.219726e-02\n",
            "epoch 82: norm of add is 1.678258 and loss is 1.220322e-02\n",
            "epoch 83: norm of add is 1.678531 and loss is 1.220918e-02\n",
            "epoch 84: norm of add is 1.678803 and loss is 1.221514e-02\n",
            "epoch 85: norm of add is 1.679076 and loss is 1.222110e-02\n",
            "epoch 86: norm of add is 1.679348 and loss is 1.222682e-02\n",
            "epoch 87: norm of add is 1.679621 and loss is 1.223278e-02\n",
            "epoch 88: norm of add is 1.679894 and loss is 1.223874e-02\n",
            "epoch 89: norm of add is 1.680166 and loss is 1.224470e-02\n",
            "epoch 90: norm of add is 1.680439 and loss is 1.225066e-02\n",
            "epoch 91: norm of add is 1.680712 and loss is 1.225662e-02\n",
            "epoch 92: norm of add is 1.680984 and loss is 1.226258e-02\n",
            "epoch 93: norm of add is 1.681257 and loss is 1.226854e-02\n",
            "epoch 94: norm of add is 1.681530 and loss is 1.227450e-02\n",
            "epoch 95: norm of add is 1.681802 and loss is 1.228046e-02\n",
            "epoch 96: norm of add is 1.682075 and loss is 1.228642e-02\n",
            "epoch 97: norm of add is 1.682348 and loss is 1.229239e-02\n",
            "epoch 98: norm of add is 1.682621 and loss is 1.229835e-02\n",
            "epoch 99: norm of add is 1.682893 and loss is 1.230454e-02\n",
            "descent\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_JWvdn9xj3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10df01be-54ee-4432-9653-28ea4570ae2d"
      },
      "source": [
        "#maximizing loss of linear combination of dictionary closest neighboors\n",
        "advers=neighboors(emb_final[0][ind],10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " friendsfriendsFriends acquaintances Friends girlfriends friendships friend buddies pals\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh47ETGtxiGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "241573a1-cc66-4ff7-817d-6813a52459b3"
      },
      "source": [
        "#dictionary closest neighboors\n",
        "embedd2=list(model.roberta.embeddings.children())[:1][0](x)[0][ind] #batch:0, word:ind\n",
        "closest_words=neighboors(embedd2,10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " friends friendFriends buddies Friendsfriends pals friendships girlfriends acquaintances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RxEDDc6SxvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "010ec861-9041-400e-d13c-0f3a45dbe907"
      },
      "source": [
        "#maximizing loss in the neighborhood\n",
        "embedd=descent(x,y,ind)[0][ind]\n",
        "closest_words0=neighboors(embedd,10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " friends friendFriends Friendsfriends classmates buddies colleagues allies cousins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69R4pBvcyXnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "185ed6cf-aa31-4ed2-c89c-e4dbc83cf239"
      },
      "source": [
        "#find max of loss of each word of the combination \n",
        "maxi=0\n",
        "amaxi=-1\n",
        "for j in range(10):\n",
        "  lss=float(model(replace(x,ind,closest_words[j]),labels=y)[0])\n",
        "  if maxi<lss:\n",
        "    maxi=lss\n",
        "    amaxi=j\n",
        "print(amaxi)\n",
        "print(tokenizer.decode(closest_words[amaxi].unsqueeze(0)))\n",
        "x = input_ids[0].unsqueeze(0).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "Friends\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBgkRaYwQNM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e970cbc3-d9fc-40e1-c975-d10cb8e8dcf5"
      },
      "source": [
        "tokenizer.decode(x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<s> Our friends won't buy this analysis, let alone the next one we propose.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl0uMdvQTprk",
        "colab_type": "text"
      },
      "source": [
        "**find adversarial function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCTfznigTtVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iid=0 #sent number 0\n",
        "ind = 2 #word number 2\n",
        "neigh = 10 #length of candidates list\n",
        "\n",
        "def find_adversarial(iid,ind,neigh):\n",
        "  x = input_ids[iid].unsqueeze(0).to(device)\n",
        "  print(tokenizer.decode(x[0]))\n",
        "  print(\"\\n\")\n",
        "  emb = predict1(x)\n",
        "  y=labels[iid].unsqueeze(0).to(device)  \n",
        "\n",
        "  emb_matrix = model.roberta.embeddings.word_embeddings.weight\n",
        "  normed_emb_matrix=F.normalize(emb_matrix, p=2, dim=1) \n",
        "\n",
        "  #dictionary closest neighboors\n",
        "  embedd2=list(model.roberta.embeddings.children())[:1][0](x)[0][ind] #batch:0, word:ind\n",
        "  print(\"closest words of the dictionary to : \"+tokenizer.decode(x[0][ind].unsqueeze(0))+\" : \")\n",
        "  closest_words=neighboors(embedd2,neigh)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  #maximizing loss in the neighborhood\n",
        "  embedd=descent(x,y,ind)[0][ind]\n",
        "  print(\"max loss with PGD in the neighborhood of : \"+tokenizer.decode(x[0][ind].unsqueeze(0))+\" : \")\n",
        "  closest_words0=neighboors(embedd,neigh)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  cand=torch.empty((neigh,len(embedd2))) \n",
        "  for t in range(neigh):\n",
        "    cand[t]=list(model.roberta.embeddings.children())[:1][0](closest_words[t].unsqueeze(0))\n",
        "  cand=cand.to(device)\n",
        "\n",
        "  a, b, c = emb.size()\n",
        "  d=cand.size()[0]\n",
        "  embdelt = torch.zeros(d,a,b,c).to(device)\n",
        "  for jj in range(d):\n",
        "    embdelt[jj][0][ind]=cand[jj]\n",
        "  embdelt=embdelt.permute(1,2,3,0)\n",
        "\n",
        "  #descent param\n",
        "  lr = 1e-4\n",
        "  n_epochs = 100\n",
        "\n",
        "  add=torch.rand((neigh),requires_grad=True).to(device)\n",
        "  add.retain_grad()\n",
        "\n",
        "  for t in range(emb.size()[2]):\n",
        "    emb[0][ind][t]=0\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    out=predict2(x,emb+torch.matmul(embdelt,add))  \n",
        "\n",
        "    criterion=torch.nn.CrossEntropyLoss()\n",
        "    loss=criterion(out,y) \n",
        "    outgrad=loss.backward(retain_graph=True)\n",
        "\n",
        "    #print(\"epoch %s: norm of add is %f and loss is %e\" %(epoch,torch.norm(add,2),loss))\n",
        "    #norm_memory[epoch]=torch.norm(torch.matmul(embdelt,add),2)\n",
        "    #loss_memory[epoch]= loss\n",
        "\n",
        "    with torch.no_grad():\n",
        "          add += lr * torch.sign(add.grad)\n",
        "        \n",
        "    add.grad.zero_()\n",
        "\n",
        "  emb_final=emb+torch.matmul(embdelt,add)\n",
        "\n",
        "  #maximizing loss of linear combination of dictionary closest neighboors\n",
        "  print(\"max loss with PGD of linear combination of dict-neighboors of : \"+tokenizer.decode(x[0][ind].unsqueeze(0))+\" : \")\n",
        "  advers=neighboors(emb_final[0][ind],10)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  #find max of loss of each word of the combination \n",
        "  maxi=0\n",
        "  amaxi=-1\n",
        "  for j in range(10):\n",
        "    lss=float(model(replace(x,ind,closest_words[j]),labels=y)[0])\n",
        "    if maxi<lss:\n",
        "      maxi=lss\n",
        "      amaxi=j\n",
        "  x = input_ids[0].unsqueeze(0).to(device)\n",
        "  print(\"max loss between all neighboors of : \"+tokenizer.decode(x[0][ind].unsqueeze(0))+\" : \")\n",
        "  print(tokenizer.decode(closest_words[amaxi].unsqueeze(0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGP8-LBIfWRH",
        "colab_type": "text"
      },
      "source": [
        "**define parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwZ7N9PtfQ0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iid=0 #sent number 0\n",
        "ind = 2 #word number 2\n",
        "neigh = 10 #length of candidates list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58Joy-unfY6u",
        "colab_type": "text"
      },
      "source": [
        "**find adversarial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui2eyKRsfTzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "2ebfb684-4eb9-4cdd-a77c-85764d0b5377"
      },
      "source": [
        "find_adversarial(iid,ind,neigh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> Our friends won't buy this analysis, let alone the next one we propose.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "\n",
            "closest words of the dictionary to :  friends : \n",
            " friends friendFriends buddies Friendsfriends pals friendships girlfriends acquaintances\n",
            "\n",
            "\n",
            "max loss with PGD in the neighborhood of :  friends : \n",
            " friends friend FriendsFriendsfriends Friend buddiesfriend girlfriends acquaintances\n",
            "\n",
            "\n",
            "max loss with PGD of linear combination of dict-neighboors of :  friends : \n",
            " friendsFriends Friendsfriends buddies acquaintances friendships friend girlfriends pals\n",
            "\n",
            "\n",
            "max loss between all neighboors of :  friends : \n",
            "Friends\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvvdt1_pfizv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "0d6b1e80-8124-4e64-f104-1a8f99f91ff8"
      },
      "source": [
        "find_adversarial(iid,3,neigh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> Our friends won't buy this analysis, let alone the next one we propose.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "\n",
            "closest words of the dictionary to :  won : \n",
            " won win Won winning winswon Winning victory winners wouldn\n",
            "\n",
            "\n",
            "max loss with PGD in the neighborhood of :  won : \n",
            " won Won win winning wins wouldn didnwon earned doesn\n",
            "\n",
            "\n",
            "max loss with PGD of linear combination of dict-neighboors of :  won : \n",
            " won wins win winning Won winners Winning victorywon victories\n",
            "\n",
            "\n",
            "max loss between all neighboors of :  won : \n",
            " Won\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9-6yCKHFvEc",
        "colab_type": "text"
      },
      "source": [
        "**load advertorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I_H1oE_gmFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b14e3331-9bea-49a1-9d11-17b23a2ef54e"
      },
      "source": [
        "!pip install advertorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting advertorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/b1/84602596294c32f49396bac9c36f1f72b00577bbcb26ebbe776e64791cac/advertorch-0.2.3.tar.gz (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 5.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: advertorch\n",
            "  Building wheel for advertorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for advertorch: filename=advertorch-0.2.3-cp36-none-any.whl size=5696220 sha256=b4ac0dbf67ea38d61bd6dd551e496daabdf8f43ebdc2a784ed9cf8f6f9884bb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/53/6e/6b2509701b0da68443fa3d4499733f5455d6d583afa8c46676\n",
            "Successfully built advertorch\n",
            "Installing collected packages: advertorch\n",
            "Successfully installed advertorch-0.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luu8zCJeWIvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from advertorch.utils import clamp\n",
        "from advertorch.utils import normalize_by_pnorm\n",
        "from advertorch.utils import clamp_by_pnorm\n",
        "from advertorch.utils import is_float_or_torch_tensor\n",
        "from advertorch.utils import batch_multiply\n",
        "from advertorch.utils import batch_clamp\n",
        "from advertorch.utils import replicate_input\n",
        "from advertorch.utils import batch_l1_proj\n",
        "\n",
        "from advertorch.attacks.base import Attack\n",
        "from advertorch.attacks.base import LabelMixin\n",
        "from advertorch.attacks.utils import rand_init_delta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdP9kZXBF_VZ",
        "colab_type": "text"
      },
      "source": [
        "**define the two forward functions of our model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyMzbpphj3Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def predict1(x): #ex: x = input_ids[0].unsqueeze(0).to(device)\n",
        "\n",
        "  emb=list(model.roberta.embeddings.children())[:1][0](x) #embedding of x\n",
        "\n",
        "  return emb\n",
        "\n",
        "def predict2(x,emb):\n",
        "\n",
        "  #some model requirements for the calculation\n",
        "  padding_idx=1\n",
        "  input_shape = x.size()\n",
        "  seq_length = input_shape[1]\n",
        "  device = torch.device(\"cuda\") \n",
        "  position_ids = create_position_ids_from_input_ids(x.to('cpu'), 1).to(device) \n",
        "  token_type_ids=torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "  #model calculations:\n",
        "  emb2=list(model.roberta.embeddings.children())[1:][0](position_ids)\n",
        "  emb3=list(model.roberta.embeddings.children())[1:][1](token_type_ids)\n",
        "  ess=list(model.roberta.embeddings.children())[1:][2](emb+emb2+emb3)  \n",
        "  out_1st=list(model.roberta.embeddings.children())[1:][3](ess)  #result of the whole embedding layer of roberta\n",
        "\n",
        "  #getting result of encoder layer of roberta\n",
        "  out_2nd=model.roberta.encoder.layer[:12][0](out_1st)\n",
        "  for i in range(1,12):\n",
        "    out_2nd=model.roberta.encoder.layer[:12][i](out_2nd[0])\n",
        "\n",
        "  #getting result of pooler layer of roberta\n",
        "  out_3nd = model.roberta.pooler(out_2nd[0])\n",
        "  out_4nd=(out_2nd[0], out_3nd,) + out_2nd[1:]\n",
        "  out_fin=out_4nd[0]\n",
        "\n",
        "  #getting result of classifier layer of roberta\n",
        "  out=model.classifier(out_fin) #this is equivalent to model(x)\n",
        "\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbyvCC7wHJyr",
        "colab_type": "text"
      },
      "source": [
        "**defining advertorch functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDJlrTkeC4qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentlong(x): #real length of an input_id sentence \n",
        "  compteur = 0\n",
        "  while compteur<len(x) and x[compteur]!=2:\n",
        "    compteur+=1\n",
        "  return compteur # compteur smallest index for which x[compteur]=2\n",
        "\n",
        "def clean(x,emb): #zero all embeddings at indexes beyond the real sentence lenght\n",
        "  size = emb.size()\n",
        "  for b in range(size[0]): #batch_size\n",
        "    sent_long=sentlong(x[b])\n",
        "    for i in range(sent_long,size[1]): #real size of the sentence \n",
        "      emb[b,i,:]=torch.zeros(size[2]) #embedding size\n",
        "  return emb\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3l-GCuYuicy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PGDAttack(Attack, LabelMixin):\n",
        "    \"\"\"\n",
        "    The projected gradient descent attack (Madry et al, 2017).\n",
        "    The attack performs nb_iter steps of size eps_iter, while always staying\n",
        "    within eps from the initial point.\n",
        "    Paper: https://arxiv.org/pdf/1706.06083.pdf\n",
        "    :param predict: forward pass function.\n",
        "    :param loss_fn: loss function.\n",
        "    :param eps: maximum distortion.\n",
        "    :param nb_iter: number of iterations.\n",
        "    :param eps_iter: attack step size.\n",
        "    :param rand_init: (optional bool) random initialization.\n",
        "    :param clip_min: mininum value per input dimension.\n",
        "    :param clip_max: maximum value per input dimension.\n",
        "    :param ord: (optional) the order of maximum distortion (inf or 2).\n",
        "    :param targeted: if the attack is targeted.\n",
        "    \"\"\"   \n",
        "\n",
        "    def __init__(\n",
        "            self, predict, loss_fn=None, eps=0.3, nb_iter=40,\n",
        "            eps_iter=0.01, rand_init=True, clip_min=0., clip_max=1.,\n",
        "            ord=np.inf, l1_sparsity=None, targeted=False):\n",
        "        \"\"\"\n",
        "        Create an instance of the PGDAttack.\n",
        "        \"\"\"\n",
        "        super(PGDAttack, self).__init__(\n",
        "            predict, loss_fn, clip_min, clip_max)\n",
        "        self.eps = eps\n",
        "        self.nb_iter = nb_iter\n",
        "        self.eps_iter = eps_iter\n",
        "        self.rand_init = rand_init\n",
        "        self.ord = ord\n",
        "        self.targeted = targeted  \n",
        "        if self.loss_fn is None:\n",
        "            self.loss_fn = nn.CrossEntropyLoss(reduction=\"sum\") #or no reduction\n",
        "        self.l1_sparsity = l1_sparsity\n",
        "        assert is_float_or_torch_tensor(self.eps_iter)\n",
        "        assert is_float_or_torch_tensor(self.eps)\n",
        "\n",
        "    def perturb(self, x, emb, ind, y=None): #ind of word to be perturbed\n",
        "        \"\"\"\n",
        "        Given examples (x, y), returns their adversarial counterparts with\n",
        "        an attack length of eps.\n",
        "        :param x: input tensor.\n",
        "        :param y: label tensor.\n",
        "                  - if None and self.targeted=False, compute y as predicted\n",
        "                    labels.\n",
        "                  - if self.targeted=True, then y must be the targeted labels.\n",
        "        :return: tensor containing perturbed inputs.\n",
        "        \"\"\"\n",
        "        emb, y = self._verify_and_process_inputs(emb, y) #???\n",
        "\n",
        "        delta = torch.zeros_like(emb)\n",
        "        delta = nn.Parameter(delta)\n",
        "        if self.rand_init: \n",
        "            rand_init_delta( \n",
        "                delta, emb, self.ord, self.eps, self.clip_min, self.clip_max)\n",
        "            delta.data = clamp(\n",
        "                emb + delta.data, min=self.clip_min, max=self.clip_max) - emb  \n",
        "\n",
        "        with torch.no_grad():\n",
        "          for t in range(delta.size()[1]):\n",
        "            if t!=ind:\n",
        "              for k in range(delta.size()[2]):\n",
        "                delta[0][t][k]=0\n",
        "\n",
        "        #delta.data = clean(x,delta.data) #clean\n",
        "\n",
        " \n",
        "        rval, norm_memory, loss_memory = perturb_iterative(\n",
        "            x, emb, ind, y, self.predict, nb_iter=self.nb_iter,\n",
        "            eps=self.eps, eps_iter=self.eps_iter,\n",
        "            loss_fn=self.loss_fn, minimize=self.targeted,\n",
        "            ord=self.ord, clip_min=self.clip_min,\n",
        "            clip_max=self.clip_max, delta_init=delta,\n",
        "            l1_sparsity=self.l1_sparsity,\n",
        "        )\n",
        "\n",
        "        return rval.data, norm_memory, loss_memory\n",
        "\n",
        "\n",
        "    def perturb_cand(self, x, emb, cand, embdelt, ind, y=None): \n",
        "        \"\"\"\n",
        "        Given examples (x, y), returns their adversarial counterparts with\n",
        "        an attack length of eps.\n",
        "        :param x: input tensor.\n",
        "        :param y: label tensor.\n",
        "                  - if None and self.targeted=False, compute y as predicted\n",
        "                    labels.\n",
        "                  - if self.targeted=True, then y must be the targeted labels.\n",
        "        :return: tensor containing perturbed inputs.\n",
        "        \"\"\"\n",
        "        emb, cand, embdelt, y = self._verify_and_process_inputs(emb, cand, embdelt, y) #???\n",
        "\n",
        "        \n",
        "        delta = (1/cand.size()[0])*torch.ones([cand.size()[0]]).to(device)\n",
        "        #delta = torch.rand(cand.size()[0]).to(device)\n",
        "        #sm= torch.sum(delta)\n",
        "        #delta = delta/sm \n",
        "        delta = nn.Parameter(delta)\n",
        "        #if self.rand_init: \n",
        "        #    rand_init_delta( \n",
        "        #        delta, emb, self.ord, self.eps, self.clip_min, self.clip_max)\n",
        "        #    delta.data = clamp(\n",
        "        #        emb + delta.data, min=self.clip_min, max=self.clip_max) - emb\n",
        "\n",
        "        #with torch.no_grad()\n",
        "\n",
        "        #delta.data = clean(x,delta.data) #clean\n",
        "\n",
        " \n",
        "        rval, norm_memory, loss_memory = perturb_iterative_cand(\n",
        "            x, emb, embdelt, ind, y, self.predict, nb_iter=self.nb_iter,\n",
        "            eps=self.eps, eps_iter=self.eps_iter,\n",
        "            loss_fn=self.loss_fn, minimize=self.targeted,\n",
        "            ord=self.ord, clip_min=self.clip_min,\n",
        "            clip_max=self.clip_max, delta_init=delta,\n",
        "            l1_sparsity=self.l1_sparsity,\n",
        "        )\n",
        "\n",
        "        return rval.data, norm_memory, loss_memory\n",
        "\n",
        "    def perturb_cand2(self, x, emb, cmb, cand, embdelt, ind, y=None): #cmb = torch.ones(10) 10=cand.size()[0]\n",
        "        \"\"\" \n",
        "        Given examples (x, y), returns their adversarial counterparts with\n",
        "        an attack length of eps.\n",
        "        :param x: input tensor.\n",
        "        :param y: label tensor.\n",
        "                  - if None and self.targeted=False, compute y as predicted\n",
        "                    labels.\n",
        "                  - if self.targeted=True, then y must be the targeted labels.\n",
        "        :return: tensor containing perturbed inputs.\n",
        "        \"\"\"\n",
        "        cmb, y = self._verify_and_process_inputs(cmb, y) #???\n",
        "\n",
        "        delta = torch.zeros_like(cmb)\n",
        "        delta = nn.Parameter(delta)\n",
        "        if self.rand_init: \n",
        "            rand_init_delta( \n",
        "                delta, cmb, self.ord, self.eps, self.clip_min, self.clip_max)   #clip_min=0\n",
        "\n",
        "        #with torch.no_grad()\n",
        "\n",
        "        #delta.data = clean(x,delta.data) #clean\n",
        "\n",
        " \n",
        "        rval, norm_memory, loss_memory = perturb_iterative_cand2(\n",
        "            x, emb, embdelt, ind, y, self.predict, nb_iter=self.nb_iter,\n",
        "            eps=self.eps, eps_iter=self.eps_iter,\n",
        "            loss_fn=self.loss_fn, minimize=self.targeted,\n",
        "            ord=self.ord, clip_min=self.clip_min,\n",
        "            clip_max=self.clip_max, delta_init=delta,\n",
        "            l1_sparsity=self.l1_sparsity,\n",
        "        )\n",
        "\n",
        "        return rval.data, norm_memory, loss_memory\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oft12PskvENo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e53745b-e99c-49b9-b7b7-ab5bb36b6657"
      },
      "source": [
        "torch.ones([5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6qNHNhRbvV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perturb_iterative(xvar, embvar, indvar, yvar, predict, nb_iter, eps, eps_iter, loss_fn,\n",
        "                      delta_init=None, minimize=False, ord=np.inf,\n",
        "                      clip_min=0.0, clip_max=1.0,\n",
        "                      l1_sparsity=None):\n",
        "    \"\"\"\n",
        "    Iteratively maximize the loss over the input. It is a shared method for\n",
        "    iterative attacks including IterativeGradientSign, LinfPGD, etc.\n",
        "    :param xvar: input data.\n",
        "    :param yvar: input labels.\n",
        "    :param predict: forward pass function.\n",
        "    :param nb_iter: number of iterations.\n",
        "    :param eps: maximum distortion.\n",
        "    :param eps_iter: attack step size.\n",
        "    :param loss_fn: loss function.\n",
        "    :param delta_init: (optional) tensor contains the random initialization.\n",
        "    :param minimize: (optional bool) whether to minimize or maximize the loss.\n",
        "    :param ord: (optional) the order of maximum distortion (inf or 2).\n",
        "    :param clip_min: mininum value per input dimension.\n",
        "    :param clip_max: maximum value per input dimension.\n",
        "    :param l1_sparsity: sparsity value for L1 projection.\n",
        "                  - if None, then perform regular L1 projection.\n",
        "                  - if float value, then perform sparse L1 descent from\n",
        "                    Algorithm 1 in https://arxiv.org/pdf/1904.13000v1.pdf\n",
        "    :return: tensor containing the perturbed input.\n",
        "    \"\"\"\n",
        "    #contain results\n",
        "    norm_memory=np.zeros((nb_iter,))\n",
        "    loss_memory=np.zeros((nb_iter,))\n",
        "    #\n",
        "\n",
        "    if delta_init is not None:\n",
        "        delta = delta_init\n",
        "    else:\n",
        "        delta = torch.zeros_like(embvar)\n",
        "\n",
        "    delta.requires_grad_()\n",
        "    for ii in range(nb_iter):\n",
        "        outputs = predict(xvar, embvar + delta)\n",
        "        loss = loss_fn(outputs, yvar)\n",
        "        if minimize:\n",
        "            loss = -loss \n",
        "\n",
        "        loss.backward()\n",
        "        if ord == np.inf: \n",
        "            grad_sign = delta.grad.data.sign()\n",
        "            grad_sign = tozero(grad_sign,indvar)\n",
        "            #print(\"before\")\n",
        "            #print(delta.data)\n",
        "            #print(grad_sign)\n",
        "            #clean(xvar,grad_sign)  #clean\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad_sign)\n",
        "            #print(delta.data)\n",
        "            delta.data = batch_clamp(eps, delta.data)\n",
        "            #print(delta.data)\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "            with torch.no_grad():\n",
        "              delta.data = tozero(delta.data,indvar)\n",
        "            #print(delta.data)\n",
        "            #print(\"after\")\n",
        "            #print(delta.data) \n",
        "                          \n",
        "\n",
        "        elif ord == 2:\n",
        "            grad = delta.grad.data\n",
        "            grad_sign = tozero(grad_sign,indvar)\n",
        "            #clean(xvar,grad)  #clean\n",
        "            grad = normalize_by_pnorm(grad)\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad)\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "            if eps is not None:\n",
        "                delta.data = clamp_by_pnorm(delta.data, ord, eps)\n",
        "\n",
        "        elif ord == 1:\n",
        "            grad = delta.grad.data\n",
        "            grad_sign = tozero(grad_sign,indvar)\n",
        "            #clean(xvar,grad)  #clean\n",
        "            abs_grad = torch.abs(grad)\n",
        "\n",
        "            batch_size = grad.size(0)\n",
        "            view = abs_grad.view(batch_size, -1)\n",
        "            view_size = view.size(1)\n",
        "            if l1_sparsity is None:\n",
        "                vals, idx = view.topk(1)\n",
        "            else:\n",
        "                vals, idx = view.topk(\n",
        "                    int(np.round((1 - l1_sparsity) * view_size)))\n",
        "\n",
        "            out = torch.zeros_like(view).scatter_(1, idx, vals)\n",
        "            out = out.view_as(grad)\n",
        "            grad = grad.sign() * (out > 0).float()\n",
        "            grad = normalize_by_pnorm(grad, p=1)\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad)\n",
        "\n",
        "            delta.data = batch_l1_proj(delta.data.cpu(), eps)\n",
        "            if embvar.is_cuda:\n",
        "                delta.data = delta.data.cuda()\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "        else:\n",
        "            error = \"Only ord = inf, ord = 1 and ord = 2 have been implemented\"\n",
        "            raise NotImplementedError(error)\n",
        "        delta.grad.data.zero_()\n",
        "        \n",
        "\n",
        "        norm_memory[ii]=torch.norm(delta.data,2) \n",
        "        loss_memory[ii]= loss \n",
        "    \n",
        " \n",
        "    emb_adv = clamp(embvar + delta, clip_min, clip_max)\n",
        "    return emb_adv, norm_memory, loss_memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JTJ4FOzqitM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perturb_iterative_cand(xvar, embvar, embdelt, indvar, yvar, predict, nb_iter, eps, eps_iter, loss_fn,\n",
        "                      delta_init=None, minimize=False, ord=np.inf,\n",
        "                      clip_min=0.0, clip_max=1.0,\n",
        "                      l1_sparsity=None):\n",
        "    \"\"\"\n",
        "    Iteratively maximize the loss over the input. It is a shared method for\n",
        "    iterative attacks including IterativeGradientSign, LinfPGD, etc.\n",
        "    :param xvar: input data.\n",
        "    :param yvar: input labels.\n",
        "    :param predict: forward pass function.\n",
        "    :param nb_iter: number of iterations.\n",
        "    :param eps: maximum distortion.\n",
        "    :param eps_iter: attack step size.\n",
        "    :param loss_fn: loss function.\n",
        "    :param delta_init: (optional) tensor contains the random initialization.\n",
        "    :param minimize: (optional bool) whether to minimize or maximize the loss.\n",
        "    :param ord: (optional) the order of maximum distortion (inf or 2).\n",
        "    :param clip_min: mininum value per input dimension.\n",
        "    :param clip_max: maximum value per input dimension.\n",
        "    :param l1_sparsity: sparsity value for L1 projection.\n",
        "                  - if None, then perform regular L1 projection.\n",
        "                  - if float value, then perform sparse L1 descent from\n",
        "                    Algorithm 1 in https://arxiv.org/pdf/1904.13000v1.pdf\n",
        "    :return: tensor containing the perturbed input.\n",
        "    \"\"\"\n",
        "    #contain results\n",
        "    norm_memory=np.zeros((nb_iter,))\n",
        "    loss_memory=np.zeros((nb_iter,))\n",
        "    \n",
        "    if delta_init is not None:\n",
        "        delta = delta_init\n",
        "\n",
        "    #.detach_() \n",
        "\n",
        "    delta.requires_grad_()\n",
        "    for ii in range(nb_iter): \n",
        "        outputs = predict(xvar, embvar + torch.matmul(embdelt,delta)) #delta[j] fois j-eme embedding qui est zerolike(embar) avec juste un embedding different \n",
        "        loss = loss_fn(outputs, yvar)\n",
        "        if minimize:\n",
        "            loss = -loss \n",
        "\n",
        "        loss.backward() \n",
        "        if ord == np.inf: \n",
        "            grad_sign = delta.grad.data.sign()\n",
        "            \n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad_sign)\n",
        "            #delta.data = batch_clamp(eps, delta.data)\n",
        "            #delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "            #                   ) - embvar.data\n",
        "            \n",
        "\n",
        "        elif ord == 2:\n",
        "            grad = delta.grad.data\n",
        "            grad_sign = tozero(grad_sign,indvar)\n",
        "            #clean(xvar,grad)  #clean\n",
        "            grad = normalize_by_pnorm(grad)\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad)\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "            if eps is not None:\n",
        "                delta.data = clamp_by_pnorm(delta.data, ord, eps)\n",
        "\n",
        "        elif ord == 1:\n",
        "            grad = delta.grad.data\n",
        "            grad_sign = tozero(grad_sign,indvar)\n",
        "            #clean(xvar,grad)  #clean\n",
        "            abs_grad = torch.abs(grad)\n",
        "\n",
        "            batch_size = grad.size(0)\n",
        "            view = abs_grad.view(batch_size, -1)\n",
        "            view_size = view.size(1)\n",
        "            if l1_sparsity is None:\n",
        "                vals, idx = view.topk(1)\n",
        "            else:\n",
        "                vals, idx = view.topk(\n",
        "                    int(np.round((1 - l1_sparsity) * view_size)))\n",
        "\n",
        "            out = torch.zeros_like(view).scatter_(1, idx, vals)\n",
        "            out = out.view_as(grad)\n",
        "            grad = grad.sign() * (out > 0).float()\n",
        "            grad = normalize_by_pnorm(grad, p=1)\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad)\n",
        "\n",
        "            delta.data = batch_l1_proj(delta.data.cpu(), eps)\n",
        "            if embvar.is_cuda:\n",
        "                delta.data = delta.data.cuda()\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "        else:\n",
        "            error = \"Only ord = inf, ord = 1 and ord = 2 have been implemented\"\n",
        "            raise NotImplementedError(error)\n",
        "        delta.grad.data.zero_()\n",
        "        print('ok')\n",
        "        norm_memory[ii]=torch.norm(delta.data,2) \n",
        "        loss_memory[ii]= loss \n",
        "    \n",
        " \n",
        "    emb_adv = clamp(embvar + delta, clip_min, clip_max)\n",
        "    return emb_adv, norm_memory, loss_memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siLCvi_WD8T_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perturb_iterative_cand2(xvar, embvar, indvar, yvar, predict, nb_iter, eps, eps_iter, loss_fn,\n",
        "                      delta_init=None, minimize=False, ord=np.inf,\n",
        "                      clip_min=0.0, clip_max=1.0,\n",
        "                      l1_sparsity=None):\n",
        "    \"\"\"\n",
        "    Iteratively maximize the loss over the input. It is a shared method for\n",
        "    iterative attacks including IterativeGradientSign, LinfPGD, etc.\n",
        "    :param xvar: input data.\n",
        "    :param yvar: input labels.\n",
        "    :param predict: forward pass function.\n",
        "    :param nb_iter: number of iterations.\n",
        "    :param eps: maximum distortion.\n",
        "    :param eps_iter: attack step size.\n",
        "    :param loss_fn: loss function.\n",
        "    :param delta_init: (optional) tensor contains the random initialization.\n",
        "    :param minimize: (optional bool) whether to minimize or maximize the loss.\n",
        "    :param ord: (optional) the order of maximum distortion (inf or 2).\n",
        "    :param clip_min: mininum value per input dimension.\n",
        "    :param clip_max: maximum value per input dimension.\n",
        "    :param l1_sparsity: sparsity value for L1 projection.\n",
        "                  - if None, then perform regular L1 projection.\n",
        "                  - if float value, then perform sparse L1 descent from\n",
        "                    Algorithm 1 in https://arxiv.org/pdf/1904.13000v1.pdf\n",
        "    :return: tensor containing the perturbed input.\n",
        "    \"\"\"\n",
        "    #contain results\n",
        "    norm_memory=np.zeros((nb_iter,))\n",
        "    loss_memory=np.zeros((nb_iter,))\n",
        "    #\n",
        "\n",
        "    if delta_init is not None:\n",
        "        delta = delta_init\n",
        "    else:\n",
        "        delta = torch.zeros_like(embvar)\n",
        "\n",
        "    delta.requires_grad_()\n",
        "    for ii in range(nb_iter):\n",
        "        outputs = predict(xvar, embvar + delta) #tenter matmul\n",
        "        loss = loss_fn(outputs, yvar)\n",
        "        if minimize:\n",
        "            loss = -loss \n",
        "\n",
        "        loss.backward()\n",
        "        if ord == np.inf: \n",
        "            grad_sign = delta.grad.data.sign()\n",
        "            grad_sign = tozero(grad_sign,indvar)\n",
        "            #print(\"before\")\n",
        "            #print(delta.data)\n",
        "            #print(grad_sign)\n",
        "            #clean(xvar,grad_sign)  #clean\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad_sign)\n",
        "            #print(delta.data)\n",
        "            delta.data = batch_clamp(eps, delta.data)\n",
        "            #print(delta.data)\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "            with torch.no_grad():\n",
        "              delta.data = tozero(delta.data,indvar)\n",
        "            #print(delta.data)\n",
        "            #print(\"after\")\n",
        "            #print(delta.data) \n",
        "                          \n",
        "\n",
        "        elif ord == 2:\n",
        "            grad = delta.grad.data\n",
        "            grad_sign = tozero(grad_sign,indvar)\n",
        "            #clean(xvar,grad)  #clean\n",
        "            grad = normalize_by_pnorm(grad)\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad)\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "            if eps is not None:\n",
        "                delta.data = clamp_by_pnorm(delta.data, ord, eps)\n",
        "\n",
        "        elif ord == 1:\n",
        "            grad = delta.grad.data\n",
        "            grad_sign = tozero(grad_sign,indvar)\n",
        "            #clean(xvar,grad)  #clean\n",
        "            abs_grad = torch.abs(grad)\n",
        "\n",
        "            batch_size = grad.size(0)\n",
        "            view = abs_grad.view(batch_size, -1)\n",
        "            view_size = view.size(1)\n",
        "            if l1_sparsity is None:\n",
        "                vals, idx = view.topk(1)\n",
        "            else:\n",
        "                vals, idx = view.topk(\n",
        "                    int(np.round((1 - l1_sparsity) * view_size)))\n",
        "\n",
        "            out = torch.zeros_like(view).scatter_(1, idx, vals)\n",
        "            out = out.view_as(grad)\n",
        "            grad = grad.sign() * (out > 0).float()\n",
        "            grad = normalize_by_pnorm(grad, p=1)\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad)\n",
        "\n",
        "            delta.data = batch_l1_proj(delta.data.cpu(), eps)\n",
        "            if embvar.is_cuda:\n",
        "                delta.data = delta.data.cuda()\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "        else:\n",
        "            error = \"Only ord = inf, ord = 1 and ord = 2 have been implemented\"\n",
        "            raise NotImplementedError(error)\n",
        "        delta.grad.data.zero_()\n",
        "        \n",
        "\n",
        "        norm_memory[ii]=torch.norm(delta.data,2) \n",
        "        loss_memory[ii]= loss \n",
        "    \n",
        " \n",
        "    emb_adv = clamp(embvar + delta, clip_min, clip_max)\n",
        "    return emb_adv, norm_memory, loss_memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE0uT6EgxKwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tozero(tens,ind):\n",
        "  tens2=torch.zeros_like(tens)\n",
        "  tens2[0][ind]=tens[0][ind]\n",
        "  return tens2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXEaGWbvzAor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tozero(predict1(x),1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ColIvU1LHy2W",
        "colab_type": "text"
      },
      "source": [
        "**gradient descent on one input WITH advertorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGz-F34ewAd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=input_ids[0].unsqueeze(0).to(device)\n",
        "emb=predict1(x)\n",
        "y=labels[0].unsqueeze(0).to(device)  \n",
        "att=PGDAttack(predict2, loss_fn=None, eps=0.3, nb_iter=100,\n",
        "            eps_iter=0.0001, rand_init=True, clip_min=0., clip_max=1.,\n",
        "            ord=np.inf, l1_sparsity=None, targeted=False)\n",
        "rval, norm_memory, loss_memory =att.perturb(x,emb,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v97xx_ZzGkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(norm_memory)\n",
        "plt.suptitle('evolution of the norm of adversarial addition')\n",
        "plt.axis()\n",
        "plt.show()\n",
        "plt.plot(loss_memory)\n",
        "plt.suptitle('evolution of the losses')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmM5Y-7DtyVL",
        "colab_type": "text"
      },
      "source": [
        "**gradient descent on batch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVTjjyQht1z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids_adv=input_ids.clone()\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset_adv = TensorDataset(input_ids_adv, labels)\n",
        " \n",
        "adv_size = len(dataset_adv)  \n",
        " \n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 10\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "dataloader_adv = DataLoader(\n",
        "            dataset_adv, # The validation samples.\n",
        "            sampler = SequentialSampler(dataset_adv), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-_ZPd-kt9oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#batch\n",
        "\n",
        "att=PGDAttack(predict2, loss_fn=None, eps=0.3, nb_iter=100,\n",
        "            eps_iter=0.001, rand_init=True, clip_min=0., clip_max=1.,\n",
        "            ord=np.inf, l1_sparsity=None, targeted=False)\n",
        "\n",
        "\n",
        "\n",
        "for incr, batch in enumerate(dataloader_adv):\n",
        "\n",
        "  x= batch[0].to(device)\n",
        "  emb=predict1(x)\n",
        "  y=batch[1].to(device)  \n",
        "  rval, norm_memory, loss_memory =att.perturb(x,emb,y)\n",
        "\n",
        "  for a in range(n_epochs):\n",
        "    plt.plot(norm_memory)\n",
        "    plt.suptitle('evolution of the norm of adversarial addition')\n",
        "    plt.axis()\n",
        "    plt.show()\n",
        "    plt.plot(loss_memory)\n",
        "    plt.suptitle('evolution of the losses')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGwStDlFvUiy",
        "colab_type": "text"
      },
      "source": [
        "# prepare adversarial dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49YvaHBZzPJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids_adv=input_ids.clone()\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset_adv = TensorDataset(input_ids_adv, labels) \n",
        " \n",
        "# Calculate the number of samples to include in each set.\n",
        "#adv_size = int(0.015 * len(dataset))\n",
        "#adv_size2 = len(dataset_adv) - adv_size\n",
        "adv_size = len(dataset)\n",
        "\n",
        "shuffled_dataset = torch.utils.data.Subset(dataset_adv, torch.randperm(adv_size).tolist()) #shuffle\n",
        " \n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 10\n",
        "\n",
        "dataloader_adv = DataLoader(\n",
        "            shuffled_dataset,  \n",
        "            sampler = SequentialSampler(shuffled_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2TZkPrF3Db5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PREPARE ADVERSARIAL DATASET WITH GRADIENT DESCENT\n",
        "\n",
        "add_data=[] #contains each perturbation for each batch\n",
        "\n",
        "att=PGDAttack(predict2, loss_fn=None, eps=0.3, nb_iter=100,\n",
        "            eps_iter=0.001, rand_init=True, clip_min=0., clip_max=1.,\n",
        "            ord=np.inf, l1_sparsity=None, targeted=False)\n",
        "\n",
        "\n",
        "incr=0\n",
        "for batch in dataloader_adv:\n",
        "\n",
        "  x= batch[0].to(device)\n",
        "  emb=predict1(x)\n",
        "  y=batch[1].to(device)  \n",
        "  rval, norm_memory, loss_memory =att.perturb(x,emb,y)\n",
        "  add_data+=[rval]\n",
        "\n",
        "  incr+=1\n",
        "\n",
        "  if len(add_data)%10==0:\n",
        "    print(len(add_data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNmGgZn2_KBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(add_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ5uLU5s0Pcm",
        "colab_type": "text"
      },
      "source": [
        "**get adversarial inputs from adversarial embeddings (NN)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG4dOeLn05f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz1dndf02c1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adversarial(x,add_embed):\n",
        "\n",
        "  #matrix of embeddings, and array of embeddings for which we want nearest neighboor\n",
        "  emb_matrix = model.roberta.embeddings.word_embeddings.weight\n",
        "  emb_array=list(model.roberta.embeddings.children())[:1][0](x) + add_embed\n",
        "\n",
        "  normed_emb_matrix=F.normalize(emb_matrix, p=2, dim=1) \n",
        "  normed_emb_array=F.normalize(emb_array, p=2, dim=2) \n",
        "\n",
        "  #find nearest neighboor\n",
        "  cosine_similarity = torch.matmul(normed_emb_array, torch.transpose(normed_emb_matrix,0,1))\n",
        "  closest_words = torch.argmax(cosine_similarity,2)\n",
        "\n",
        "  return closest_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6_LE9f72n3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to know if the adversarial input dataset does differ from the initial input dataset\n",
        "def compare(x,closest_words): \n",
        "  diff=0\n",
        "  for i in range(x.size()[0]):\n",
        "    for j in range(x.size()[1]):\n",
        "      if not(x[i,j]==closest_words[i,j]):\n",
        "        diff+=1\n",
        "  return 100*diff/(x.size()[0]*x.size()[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9-lPYP-5X3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x: any input_id batch for which we want adversarial\n",
        "#x= shuffled_dataset[:10][0].to(device)\n",
        "\n",
        "comp = np.zeros([len(add_data)])\n",
        "\n",
        "for incr, batch in enumerate(dataloader_adv):\n",
        "\n",
        "  if incr>= len(add_data):\n",
        "    break\n",
        "\n",
        "  x= batch[0].to(device)\n",
        "  closest_words = adversarial(x,add_data[incr])\n",
        "\n",
        "  comp[incr]=compare(x,closest_words)\n",
        "\n",
        "plt.plot(comp)\n",
        "plt.suptitle('percentage of changed words for each batch')\n",
        "plt.axis()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTbQxM-qgbzK",
        "colab_type": "text"
      },
      "source": [
        "**loss of our model on adversarial dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80vT_WNUvZKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#COMPARE VALIDATION OF MODEL ON INITIAL DATASET AND ADVERSARIAL DATASET\n",
        " \n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "\n",
        "# ========================================\n",
        "#               Validation\n",
        "# ========================================\n",
        "# After the completion of each training epoch, measure our performance on\n",
        "# our validation set.\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables  \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "total_eval_accuracy_adv = 0\n",
        "total_eval_loss_adv = 0\n",
        "\n",
        "incr=0\n",
        "# Evaluate data for one epoch\n",
        "for batch in dataloader_adv:\n",
        "\n",
        "    if incr>=len(add_data):\n",
        "      break\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[1].to(device)\n",
        "\n",
        "    b_input_ids_adv = batch[0].to(device)\n",
        "    b_labels_adv = batch[1].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        (loss, logits) = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                labels=b_labels)\n",
        "        \n",
        "        #(loss_adv, logits_adv) = model(adversarial(b_input_ids_adv,add_data[incr]), \n",
        "        #                        token_type_ids=None, \n",
        "        #                        labels=b_labels)\n",
        "\n",
        "        #batch\n",
        "        x = b_input_ids_adv\n",
        "        emb = predict1(x)\n",
        "        out = predict2(x,emb+add_data[incr])\n",
        "        criterion=torch.nn.CrossEntropyLoss()\n",
        "        loss_adv=criterion(out,b_labels_adv) \n",
        "        logits_adv = out\n",
        "\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "    total_eval_loss_adv += loss_adv.item()\n",
        "\n",
        "    # Move logits and labels to CPU \n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    logits_adv = logits_adv.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    total_eval_accuracy_adv += flat_accuracy(logits_adv, label_ids)\n",
        "\n",
        "    incr+=1\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy /len(add_data) # len(dataloader_adv)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "avg_val_accuracy_adv = total_eval_accuracy_adv /len(add_data) # len(dataloader_adv)\n",
        "print(\"  Accuracy on adversarial: {0:.2f}\".format(avg_val_accuracy_adv))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss /len(add_data) # len(dataloader_adv)\n",
        "avg_val_loss_adv = total_eval_loss_adv /len(add_data) # len(dataloader_adv)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Validation took: {:}\".format(validation_time))\n",
        "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\" Valid. Accur.: {:}\".format(avg_val_accuracy))\n",
        "print(\"  Validation Loss on adversarial: {0:.2f}\".format(avg_val_loss_adv))\n",
        "print(\" Valid. Accur. on adversarial: {:}\".format(avg_val_accuracy_adv))\n",
        "\n",
        "print(\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQM0vXQleF8H",
        "colab_type": "text"
      },
      "source": [
        "**training our model on adversarial dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOxlE_bMgfon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset = torch.utils.data.Subset(shuffled_dataset, range(train_size))\n",
        "val_dataset = torch.utils.data.Subset(shuffled_dataset, range(train_size,train_size+val_size))\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 10\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = SequentialSampler(train_dataset),  \n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6NIXQ0too83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reload model\n",
        "\n",
        "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model2 = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model2.cuda()\n",
        "\n",
        "\n",
        "# see https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "\n",
        "from transformers import AdamW\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer2 = AdamW(model2.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler2 = get_linear_schedule_with_warmup(optimizer2, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I87guLjIr91L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model2.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model2.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        if step<len(add_data):\n",
        "          loss, logits = model2(adversarial(b_input_ids,add_data[step]), \n",
        "                              token_type_ids=None, \n",
        "                              labels=b_labels)\n",
        "        else:\n",
        "          loss, logits = model2(b_input_ids, \n",
        "                              token_type_ids=None, \n",
        "                              labels=b_labels)\n",
        "\n",
        "\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model2.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer2.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler2.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model2.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model2(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}