{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plot_attack_roberta.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6003c0e8eb614251a4b46f4736e62da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f7a9b9e93ede4f66907529f066dd6c58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9891c44d9cfb44deb15d21c9058c1da0",
              "IPY_MODEL_5a16df0c3962446bad551af22a539577"
            ]
          }
        },
        "f7a9b9e93ede4f66907529f066dd6c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9891c44d9cfb44deb15d21c9058c1da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39aaa93027d440c1aa7bcdceeb258c12",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aedb6d05ee5340799a2e5f6ca9c00479"
          }
        },
        "5a16df0c3962446bad551af22a539577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d875c9e6c792482dac34a859940d0fbb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:03&lt;00:00, 267kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6dc02a48de32470da9e0768f2dff1ec3"
          }
        },
        "39aaa93027d440c1aa7bcdceeb258c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aedb6d05ee5340799a2e5f6ca9c00479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d875c9e6c792482dac34a859940d0fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6dc02a48de32470da9e0768f2dff1ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66ccb6260b0a4c0db4fa8f007e6f505c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_72fb4922562f44adb4c52cef39f8182b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_970804f381f944d78a251421d83835d7",
              "IPY_MODEL_30ee11f8f700443aac06c96a233ec46c"
            ]
          }
        },
        "72fb4922562f44adb4c52cef39f8182b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "970804f381f944d78a251421d83835d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7242d0b75e4e444a95e249af21d0b3c0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4b0a267989a476e9f9b2a6f7409d628"
          }
        },
        "30ee11f8f700443aac06c96a233ec46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b89a2252875d4cdb8a5dd7fcf4593ef8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 566kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_226db3a6f9fa4ca5ad8695318886102f"
          }
        },
        "7242d0b75e4e444a95e249af21d0b3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4b0a267989a476e9f9b2a6f7409d628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b89a2252875d4cdb8a5dd7fcf4593ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "226db3a6f9fa4ca5ad8695318886102f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df589f19bf8042ca9592980d77d72cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_46e18df6d4044a40b158309cfbb1901f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f989e23452d4c7e89ce977bd1888d42",
              "IPY_MODEL_0ceb549eb9e343bdb31c7c6bb355ecb1"
            ]
          }
        },
        "46e18df6d4044a40b158309cfbb1901f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f989e23452d4c7e89ce977bd1888d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_681cc59e824f45a6819492c30e5d05ef",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14caf52b8dde48d1a8fa5bd5a229f838"
          }
        },
        "0ceb549eb9e343bdb31c7c6bb355ecb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc67095af96f45339d62b7b4afe0e1a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 3.15kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7897d28cadad444ca5a38bf2fe8f8bd2"
          }
        },
        "681cc59e824f45a6819492c30e5d05ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14caf52b8dde48d1a8fa5bd5a229f838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc67095af96f45339d62b7b4afe0e1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7897d28cadad444ca5a38bf2fe8f8bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93f2c03ec8614e0b9385a155c55c1777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ca0af8495574140bf3da2357f59017b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4148cfe9a66a4820881c4bba457aa925",
              "IPY_MODEL_d5fa500a862f4ead9c430cae6fff0e4d"
            ]
          }
        },
        "8ca0af8495574140bf3da2357f59017b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4148cfe9a66a4820881c4bba457aa925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c1c2293f60845ebb621c3555c6ec3c2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_022ab44783304923a04b53e29268c224"
          }
        },
        "d5fa500a862f4ead9c430cae6fff0e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf5eb971f78c4a65a90240fe240618f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:30&lt;00:00, 16.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ba2f2332d0244c29cf1d55f807295e8"
          }
        },
        "2c1c2293f60845ebb621c3555c6ec3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "022ab44783304923a04b53e29268c224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf5eb971f78c4a65a90240fe240618f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ba2f2332d0244c29cf1d55f807295e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMqUFyziS_tQ",
        "colab_type": "text"
      },
      "source": [
        "**Installations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "135PswSfSQYr",
        "colab_type": "code",
        "outputId": "83447b05-2044-44af-db9c-bf3e0ccd86fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        }
      },
      "source": [
        "  !pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 14.7MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=4d1112f1b6fe7d05b257a3c71f6bc824a64919f317b0ce3badf39104889c6a63\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm6kmrSxS1Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIJYSJXyTZ-8",
        "colab_type": "text"
      },
      "source": [
        "**Downloading CoLA data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctpdr9tiS1i6",
        "colab_type": "code",
        "outputId": "f64e46fe-b862-4a7e-a3fe-a3982b47752a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=87cbad9bfeb81a01dc5cf59d743ab0e57aa1ab7b9c856c590f830b9f09a30cf4\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yrzqVSrS49w",
        "colab_type": "code",
        "outputId": "da9c0529-1883-4486-b631-c288e9984c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-5aFGES7K4",
        "colab_type": "code",
        "outputId": "67b11226-3aab-4836-efe2-bbc32ebcb806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vww0Zu1UkL3T",
        "colab_type": "text"
      },
      "source": [
        "**extract and tokenize data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiRnG8PHkLAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "sentences=[]\n",
        "labels=[]\n",
        "with open(\"./cola_public/raw/in_domain_train.tsv\") as tsvfile:\n",
        "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
        "    for line in tsvreader:\n",
        "        sentences += [line[3]]\n",
        "        labels += [int(line[1])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIxZpDwwku0f",
        "colab_type": "code",
        "outputId": "ac29f6ac-4cab-4bf0-f752-99bdcf5330df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "6003c0e8eb614251a4b46f4736e62da5",
            "f7a9b9e93ede4f66907529f066dd6c58",
            "9891c44d9cfb44deb15d21c9058c1da0",
            "5a16df0c3962446bad551af22a539577",
            "39aaa93027d440c1aa7bcdceeb258c12",
            "aedb6d05ee5340799a2e5f6ca9c00479",
            "d875c9e6c792482dac34a859940d0fbb",
            "6dc02a48de32470da9e0768f2dff1ec3",
            "66ccb6260b0a4c0db4fa8f007e6f505c",
            "72fb4922562f44adb4c52cef39f8182b",
            "970804f381f944d78a251421d83835d7",
            "30ee11f8f700443aac06c96a233ec46c",
            "7242d0b75e4e444a95e249af21d0b3c0",
            "e4b0a267989a476e9f9b2a6f7409d628",
            "b89a2252875d4cdb8a5dd7fcf4593ef8",
            "226db3a6f9fa4ca5ad8695318886102f"
          ]
        }
      },
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base') \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6003c0e8eb614251a4b46f4736e62da5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66ccb6260b0a4c0db4fa8f007e6f505c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xlptfs4kr4K",
        "colab_type": "code",
        "outputId": "0f6eebba-1b4a-4200-dcc8-2c4ba4edf98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# ici juste un tour pour voir quelle est la taille max . on visera un peu pls haut par sécurité.\n",
        "\n",
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZjuY-eSkxhv",
        "colab_type": "code",
        "outputId": "abde8c7f-aeb0-4e66-cd40-1384c88497f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "for sent in sentences:\n",
        "  encoded_dict = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "  # Add the encoded sentence to the list.    \n",
        "  input_ids.append(encoded_dict)\n",
        "    \n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([    0,  1541,   964,   351,    75,   907,    42,  1966,     6,   905,\n",
            "         1937,     5,   220,    65,    52, 15393,     4,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBAKtB2WlCyE",
        "colab_type": "text"
      },
      "source": [
        "**prepare training and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8h1pF8DlF_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91gw-CHSlJp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snao8QB4lNyq",
        "colab_type": "text"
      },
      "source": [
        "**create model to be finetuned**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUvSSGWqlLqb",
        "colab_type": "code",
        "outputId": "be713a48-c368-4fdd-9afb-b838660cfcc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "df589f19bf8042ca9592980d77d72cbe",
            "46e18df6d4044a40b158309cfbb1901f",
            "0f989e23452d4c7e89ce977bd1888d42",
            "0ceb549eb9e343bdb31c7c6bb355ecb1",
            "681cc59e824f45a6819492c30e5d05ef",
            "14caf52b8dde48d1a8fa5bd5a229f838",
            "bc67095af96f45339d62b7b4afe0e1a6",
            "7897d28cadad444ca5a38bf2fe8f8bd2",
            "93f2c03ec8614e0b9385a155c55c1777",
            "8ca0af8495574140bf3da2357f59017b",
            "4148cfe9a66a4820881c4bba457aa925",
            "d5fa500a862f4ead9c430cae6fff0e4d",
            "2c1c2293f60845ebb621c3555c6ec3c2",
            "022ab44783304923a04b53e29268c224",
            "cf5eb971f78c4a65a90240fe240618f2",
            "2ba2f2332d0244c29cf1d55f807295e8"
          ]
        }
      },
      "source": [
        "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df589f19bf8042ca9592980d77d72cbe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93f2c03ec8614e0b9385a155c55c1777",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px8Ow-o8lfDj",
        "colab_type": "text"
      },
      "source": [
        "**prepare finetuning training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODfEZF5elhhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# see https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "\n",
        "from transformers import AdamW\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v_fiLYylj5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp63EsBelle2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g_KM56nlnEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gLgOukEloyI",
        "colab_type": "code",
        "outputId": "228cf63e-a482-4c64-a3f6-162872ad6122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79BRC_p6luzn",
        "colab_type": "text"
      },
      "source": [
        "**train.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeQxc__clrTG",
        "colab_type": "code",
        "outputId": "850cf734-83c7-4f6e-ac73-c36464c93ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:18.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:44.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:10.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:36.\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:02:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.50\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:19.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:45.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:37.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:02:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.38\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:19.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:45.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:37.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:02:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.47\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:19.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:45.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:37.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:02:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.45\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:10:51 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrY6DDZ5u9Nr",
        "colab_type": "text"
      },
      "source": [
        "# Gradient sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwKvrKdTs-C5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers.modeling_utils import create_position_ids_from_input_ids\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoLotHxVpf06",
        "colab_type": "text"
      },
      "source": [
        "**gradient descent on one input WITHOUT advertorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkI1XvwoP2SU",
        "colab_type": "code",
        "outputId": "0fcc9f4c-6f01-4c3c-f2b9-1e738237c43c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#batch\n",
        "x = input_ids[0].unsqueeze(0).to(device)\n",
        "\n",
        "#descent param\n",
        "lr = 1e-4\n",
        "n_epochs = 100\n",
        "\n",
        "#contain results\n",
        "norm_memory=np.zeros((n_epochs,))\n",
        "loss_memory=np.zeros((n_epochs,))\n",
        "\n",
        "#adversarial addition\n",
        "add=torch.zeros([1,64,768], dtype=torch.float, requires_grad=True).to(device)\n",
        "for j in range(64):\n",
        "  for i in range(768):\n",
        "    add[0,j,i]+= 1.5e-4*random.random() #j'ajoute un delta aux embedding de tous les mots de la phrase\n",
        "addr=add.clone()\n",
        "\n",
        "add.retain_grad()\n",
        "\n",
        "#some model requirements for the calculation\n",
        "padding_idx=1\n",
        "input_shape = x.size()\n",
        "seq_length = input_shape[1]\n",
        "device = torch.device(\"cuda\") \n",
        "position_ids = create_position_ids_from_input_ids(input_ids[0].unsqueeze(0), 1).to(device) \n",
        "token_type_ids=torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "#model calculations:\n",
        "\n",
        "emb=list(model.roberta.embeddings.children())[:1][0](x) #embedding of x\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  emb2=list(model.roberta.embeddings.children())[1:][0](position_ids)\n",
        "  emb3=list(model.roberta.embeddings.children())[1:][1](token_type_ids)\n",
        "  ess=list(model.roberta.embeddings.children())[1:][2](emb+add+emb2+emb3) #emb+add!\n",
        "  out_1st=list(model.roberta.embeddings.children())[1:][3](ess)  #result of the whole embedding layer of roberta\n",
        "\n",
        "  #getting result of encoder layer of roberta\n",
        "  out_2nd=model.roberta.encoder.layer[:12][0](out_1st)\n",
        "  for i in range(1,12):\n",
        "    out_2nd=model.roberta.encoder.layer[:12][i](out_2nd[0])\n",
        "\n",
        "  #getting result of pooler layer of roberta\n",
        "  out_3nd = model.roberta.pooler(out_2nd[0])\n",
        "  out_4nd=(out_2nd[0], out_3nd,) + out_2nd[1:]\n",
        "  out_fin=out_4nd[0]\n",
        "\n",
        "  #getting result of classifier layer of roberta\n",
        "  out=model.classifier(out_fin) #this is equivalent to model(x)\n",
        "\n",
        "  criterion=torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  loss=criterion(out,labels[0].unsqueeze(0).to(device)) \n",
        "\n",
        "  outgrad=loss.backward(retain_graph=True)\n",
        "\n",
        "  print(\"epoch %s: norm of add is %f and loss is %e\" %(epoch,torch.norm(add,2),loss))\n",
        "  norm_memory[epoch]=torch.norm(add,2)\n",
        "  loss_memory[epoch]= loss\n",
        "\n",
        "  with torch.no_grad():\n",
        "        add += lr * torch.sign(add.grad)\n",
        "    \n",
        "  add.grad.zero_()\n",
        "  \n",
        "  \n",
        "\n",
        "print(\"descent\")\n",
        "plt.plot(norm_memory)\n",
        "plt.suptitle('evolution of the norm of adversarial addition')\n",
        "plt.axis()\n",
        "plt.show()\n",
        "plt.plot(loss_memory)\n",
        "plt.suptitle('evolution of the losses')\n",
        "plt.show()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0: norm of add is 0.019238 and loss is 8.339167e-03\n",
            "epoch 1: norm of add is 0.029131 and loss is 8.679152e-03\n",
            "epoch 2: norm of add is 0.046094 and loss is 8.955956e-03\n",
            "epoch 3: norm of add is 0.057797 and loss is 9.208202e-03\n",
            "epoch 4: norm of add is 0.075754 and loss is 9.452820e-03\n",
            "epoch 5: norm of add is 0.087967 and loss is 9.709597e-03\n",
            "epoch 6: norm of add is 0.105615 and loss is 9.977818e-03\n",
            "epoch 7: norm of add is 0.118928 and loss is 1.027560e-02\n",
            "epoch 8: norm of add is 0.136606 and loss is 1.059270e-02\n",
            "epoch 9: norm of add is 0.151236 and loss is 1.091790e-02\n",
            "epoch 10: norm of add is 0.168622 and loss is 1.126146e-02\n",
            "epoch 11: norm of add is 0.183075 and loss is 1.160526e-02\n",
            "epoch 12: norm of add is 0.199429 and loss is 1.197028e-02\n",
            "epoch 13: norm of add is 0.213279 and loss is 1.235127e-02\n",
            "epoch 14: norm of add is 0.228816 and loss is 1.276302e-02\n",
            "epoch 15: norm of add is 0.242513 and loss is 1.320291e-02\n",
            "epoch 16: norm of add is 0.257140 and loss is 1.366806e-02\n",
            "epoch 17: norm of add is 0.270521 and loss is 1.419330e-02\n",
            "epoch 18: norm of add is 0.285023 and loss is 1.475501e-02\n",
            "epoch 19: norm of add is 0.298564 and loss is 1.538658e-02\n",
            "epoch 20: norm of add is 0.313003 and loss is 1.607943e-02\n",
            "epoch 21: norm of add is 0.326710 and loss is 1.683843e-02\n",
            "epoch 22: norm of add is 0.340920 and loss is 1.767063e-02\n",
            "epoch 23: norm of add is 0.354505 and loss is 1.859093e-02\n",
            "epoch 24: norm of add is 0.368418 and loss is 1.963782e-02\n",
            "epoch 25: norm of add is 0.381855 and loss is 2.076435e-02\n",
            "epoch 26: norm of add is 0.395739 and loss is 2.211833e-02\n",
            "epoch 27: norm of add is 0.409516 and loss is 2.357984e-02\n",
            "epoch 28: norm of add is 0.423489 and loss is 2.534485e-02\n",
            "epoch 29: norm of add is 0.437233 and loss is 2.734101e-02\n",
            "epoch 30: norm of add is 0.451383 and loss is 2.982414e-02\n",
            "epoch 31: norm of add is 0.465166 and loss is 3.279114e-02\n",
            "epoch 32: norm of add is 0.479663 and loss is 3.659737e-02\n",
            "epoch 33: norm of add is 0.493756 and loss is 4.138672e-02\n",
            "epoch 34: norm of add is 0.508143 and loss is 4.748452e-02\n",
            "epoch 35: norm of add is 0.522475 and loss is 5.537701e-02\n",
            "epoch 36: norm of add is 0.536403 and loss is 6.589651e-02\n",
            "epoch 37: norm of add is 0.550043 and loss is 8.033419e-02\n",
            "epoch 38: norm of add is 0.563452 and loss is 1.006458e-01\n",
            "epoch 39: norm of add is 0.576406 and loss is 1.297507e-01\n",
            "epoch 40: norm of add is 0.588711 and loss is 1.717140e-01\n",
            "epoch 41: norm of add is 0.600679 and loss is 2.312564e-01\n",
            "epoch 42: norm of add is 0.612211 and loss is 3.127994e-01\n",
            "epoch 43: norm of add is 0.623507 and loss is 4.187980e-01\n",
            "epoch 44: norm of add is 0.634952 and loss is 5.447807e-01\n",
            "epoch 45: norm of add is 0.645956 and loss is 6.764562e-01\n",
            "epoch 46: norm of add is 0.656506 and loss is 7.999913e-01\n",
            "epoch 47: norm of add is 0.665670 and loss is 9.152867e-01\n",
            "epoch 48: norm of add is 0.673091 and loss is 1.031109e+00\n",
            "epoch 49: norm of add is 0.679513 and loss is 1.151667e+00\n",
            "epoch 50: norm of add is 0.685286 and loss is 1.278659e+00\n",
            "epoch 51: norm of add is 0.691210 and loss is 1.412191e+00\n",
            "epoch 52: norm of add is 0.697128 and loss is 1.552468e+00\n",
            "epoch 53: norm of add is 0.703296 and loss is 1.702096e+00\n",
            "epoch 54: norm of add is 0.709591 and loss is 1.865421e+00\n",
            "epoch 55: norm of add is 0.715799 and loss is 2.028935e+00\n",
            "epoch 56: norm of add is 0.723011 and loss is 2.172719e+00\n",
            "epoch 57: norm of add is 0.730197 and loss is 2.291905e+00\n",
            "epoch 58: norm of add is 0.736700 and loss is 2.396604e+00\n",
            "epoch 59: norm of add is 0.743577 and loss is 2.528570e+00\n",
            "epoch 60: norm of add is 0.751689 and loss is 2.697415e+00\n",
            "epoch 61: norm of add is 0.759937 and loss is 2.806278e+00\n",
            "epoch 62: norm of add is 0.767502 and loss is 2.878521e+00\n",
            "epoch 63: norm of add is 0.773889 and loss is 2.939381e+00\n",
            "epoch 64: norm of add is 0.778765 and loss is 2.985672e+00\n",
            "epoch 65: norm of add is 0.783953 and loss is 3.034111e+00\n",
            "epoch 66: norm of add is 0.788338 and loss is 3.079082e+00\n",
            "epoch 67: norm of add is 0.793729 and loss is 3.125904e+00\n",
            "epoch 68: norm of add is 0.798241 and loss is 3.168648e+00\n",
            "epoch 69: norm of add is 0.803391 and loss is 3.212141e+00\n",
            "epoch 70: norm of add is 0.807682 and loss is 3.247539e+00\n",
            "epoch 71: norm of add is 0.812199 and loss is 3.283249e+00\n",
            "epoch 72: norm of add is 0.815929 and loss is 3.312023e+00\n",
            "epoch 73: norm of add is 0.819599 and loss is 3.341480e+00\n",
            "epoch 74: norm of add is 0.822508 and loss is 3.367696e+00\n",
            "epoch 75: norm of add is 0.825699 and loss is 3.395586e+00\n",
            "epoch 76: norm of add is 0.828386 and loss is 3.420835e+00\n",
            "epoch 77: norm of add is 0.831938 and loss is 3.448009e+00\n",
            "epoch 78: norm of add is 0.834955 and loss is 3.473818e+00\n",
            "epoch 79: norm of add is 0.838998 and loss is 3.500650e+00\n",
            "epoch 80: norm of add is 0.842255 and loss is 3.529243e+00\n",
            "epoch 81: norm of add is 0.846840 and loss is 3.557909e+00\n",
            "epoch 82: norm of add is 0.850357 and loss is 3.591421e+00\n",
            "epoch 83: norm of add is 0.855320 and loss is 3.624672e+00\n",
            "epoch 84: norm of add is 0.859348 and loss is 3.658883e+00\n",
            "epoch 85: norm of add is 0.864966 and loss is 3.689489e+00\n",
            "epoch 86: norm of add is 0.870234 and loss is 3.717324e+00\n",
            "epoch 87: norm of add is 0.876761 and loss is 3.742805e+00\n",
            "epoch 88: norm of add is 0.882660 and loss is 3.766906e+00\n",
            "epoch 89: norm of add is 0.889976 and loss is 3.789811e+00\n",
            "epoch 90: norm of add is 0.896129 and loss is 3.811978e+00\n",
            "epoch 91: norm of add is 0.904364 and loss is 3.833485e+00\n",
            "epoch 92: norm of add is 0.910543 and loss is 3.854278e+00\n",
            "epoch 93: norm of add is 0.919793 and loss is 3.874568e+00\n",
            "epoch 94: norm of add is 0.925780 and loss is 3.894082e+00\n",
            "epoch 95: norm of add is 0.935829 and loss is 3.913095e+00\n",
            "epoch 96: norm of add is 0.941503 and loss is 3.931284e+00\n",
            "epoch 97: norm of add is 0.952057 and loss is 3.949008e+00\n",
            "epoch 98: norm of add is 0.957387 and loss is 3.965801e+00\n",
            "epoch 99: norm of add is 0.968352 and loss is 3.982321e+00\n",
            "descent\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9-6yCKHFvEc",
        "colab_type": "text"
      },
      "source": [
        "**load advertorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I_H1oE_gmFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "883230b3-ce2e-41f5-e750-7a6c19d7f85d"
      },
      "source": [
        "!pip install advertorch"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting advertorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/68/b94c0ced6745f81383a892afe4f39e7971f0d130298b30c108dabbc45329/advertorch-0.2.2.tar.gz (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 2.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: advertorch\n",
            "  Building wheel for advertorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for advertorch: filename=advertorch-0.2.2-cp36-none-any.whl size=5696025 sha256=1f75d60f58b4423c692047b6c28d79326d697dd5a892b48c4e330c39b9cd8504\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/a6/50/56abaca033ac489db974e0cb8b777ca96a3ea22ba7806c0cbe\n",
            "Successfully built advertorch\n",
            "Installing collected packages: advertorch\n",
            "Successfully installed advertorch-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luu8zCJeWIvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from advertorch.utils import clamp\n",
        "from advertorch.utils import normalize_by_pnorm\n",
        "from advertorch.utils import clamp_by_pnorm\n",
        "from advertorch.utils import is_float_or_torch_tensor\n",
        "from advertorch.utils import batch_multiply\n",
        "from advertorch.utils import batch_clamp\n",
        "from advertorch.utils import replicate_input\n",
        "from advertorch.utils import batch_l1_proj\n",
        "\n",
        "from advertorch.attacks.base import Attack\n",
        "from advertorch.attacks.base import LabelMixin\n",
        "from advertorch.attacks.utils import rand_init_delta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdP9kZXBF_VZ",
        "colab_type": "text"
      },
      "source": [
        "**define the two forward functions of our model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyMzbpphj3Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def predict1(x): #x = input_ids[0].unsqueeze(0).to(device)\n",
        "\n",
        "  emb=list(model.roberta.embeddings.children())[:1][0](x) #embedding of x\n",
        "\n",
        "  return emb\n",
        "\n",
        "def predict2(x,emb):\n",
        "\n",
        "  #some model requirements for the calculation\n",
        "  padding_idx=1\n",
        "  input_shape = x.size()\n",
        "  seq_length = input_shape[1]\n",
        "  device = torch.device(\"cuda\") \n",
        "  position_ids = create_position_ids_from_input_ids(input_ids[0].unsqueeze(0), 1).to(device) \n",
        "  token_type_ids=torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "  #model calculations:\n",
        "  emb2=list(model.roberta.embeddings.children())[1:][0](position_ids)\n",
        "  emb3=list(model.roberta.embeddings.children())[1:][1](token_type_ids)\n",
        "  ess=list(model.roberta.embeddings.children())[1:][2](emb+emb2+emb3)  \n",
        "  out_1st=list(model.roberta.embeddings.children())[1:][3](ess)  #result of the whole embedding layer of roberta\n",
        "\n",
        "  #getting result of encoder layer of roberta\n",
        "  out_2nd=model.roberta.encoder.layer[:12][0](out_1st)\n",
        "  for i in range(1,12):\n",
        "    out_2nd=model.roberta.encoder.layer[:12][i](out_2nd[0])\n",
        "\n",
        "  #getting result of pooler layer of roberta\n",
        "  out_3nd = model.roberta.pooler(out_2nd[0])\n",
        "  out_4nd=(out_2nd[0], out_3nd,) + out_2nd[1:]\n",
        "  out_fin=out_4nd[0]\n",
        "\n",
        "  #getting result of classifier layer of roberta\n",
        "  out=model.classifier(out_fin) #this is equivalent to model(x)\n",
        "\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbyvCC7wHJyr",
        "colab_type": "text"
      },
      "source": [
        "**defining advertorch functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ytaPekOVtUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PGDAttack(Attack, LabelMixin):\n",
        "    \"\"\"\n",
        "    The projected gradient descent attack (Madry et al, 2017).\n",
        "    The attack performs nb_iter steps of size eps_iter, while always staying\n",
        "    within eps from the initial point.\n",
        "    Paper: https://arxiv.org/pdf/1706.06083.pdf\n",
        "    :param predict: forward pass function.\n",
        "    :param loss_fn: loss function.\n",
        "    :param eps: maximum distortion.\n",
        "    :param nb_iter: number of iterations.\n",
        "    :param eps_iter: attack step size.\n",
        "    :param rand_init: (optional bool) random initialization.\n",
        "    :param clip_min: mininum value per input dimension.\n",
        "    :param clip_max: maximum value per input dimension.\n",
        "    :param ord: (optional) the order of maximum distortion (inf or 2).\n",
        "    :param targeted: if the attack is targeted.\n",
        "    \"\"\"  \n",
        "\n",
        "    def __init__(\n",
        "            self, predict, loss_fn=None, eps=0.3, nb_iter=40,\n",
        "            eps_iter=0.01, rand_init=True, clip_min=0., clip_max=1.,\n",
        "            ord=np.inf, l1_sparsity=None, targeted=False):\n",
        "        \"\"\"\n",
        "        Create an instance of the PGDAttack.\n",
        "        \"\"\"\n",
        "        super(PGDAttack, self).__init__(\n",
        "            predict, loss_fn, clip_min, clip_max)\n",
        "        self.eps = eps\n",
        "        self.nb_iter = nb_iter\n",
        "        self.eps_iter = eps_iter\n",
        "        self.rand_init = rand_init\n",
        "        self.ord = ord\n",
        "        self.targeted = targeted \n",
        "        if self.loss_fn is None:\n",
        "            self.loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "        self.l1_sparsity = l1_sparsity\n",
        "        assert is_float_or_torch_tensor(self.eps_iter)\n",
        "        assert is_float_or_torch_tensor(self.eps)\n",
        "\n",
        "    def perturb(self, x, emb, y=None):\n",
        "        \"\"\"\n",
        "        Given examples (x, y), returns their adversarial counterparts with\n",
        "        an attack length of eps.\n",
        "        :param x: input tensor.\n",
        "        :param y: label tensor.\n",
        "                  - if None and self.targeted=False, compute y as predicted\n",
        "                    labels.\n",
        "                  - if self.targeted=True, then y must be the targeted labels.\n",
        "        :return: tensor containing perturbed inputs.\n",
        "        \"\"\"\n",
        "        emb, y = self._verify_and_process_inputs(emb, y) #???\n",
        "\n",
        "        delta = torch.zeros_like(emb)\n",
        "        delta = nn.Parameter(delta)\n",
        "        if self.rand_init: \n",
        "            rand_init_delta(\n",
        "                delta, emb, self.ord, self.eps, self.clip_min, self.clip_max)\n",
        "            delta.data = clamp(\n",
        "                emb + delta.data, min=self.clip_min, max=self.clip_max) - emb\n",
        "\n",
        "        rval, norm_memory, loss_memory = perturb_iterative(\n",
        "            x, emb, y, self.predict, nb_iter=self.nb_iter,\n",
        "            eps=self.eps, eps_iter=self.eps_iter,\n",
        "            loss_fn=self.loss_fn, minimize=self.targeted,\n",
        "            ord=self.ord, clip_min=self.clip_min,\n",
        "            clip_max=self.clip_max, delta_init=delta,\n",
        "            l1_sparsity=self.l1_sparsity,\n",
        "        )\n",
        "\n",
        "        return rval.data, norm_memory, loss_memory\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6qNHNhRbvV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perturb_iterative(xvar, embvar, yvar, predict, nb_iter, eps, eps_iter, loss_fn,\n",
        "                      delta_init=None, minimize=False, ord=np.inf,\n",
        "                      clip_min=0.0, clip_max=1.0,\n",
        "                      l1_sparsity=None):\n",
        "    \"\"\"\n",
        "    Iteratively maximize the loss over the input. It is a shared method for\n",
        "    iterative attacks including IterativeGradientSign, LinfPGD, etc.\n",
        "    :param xvar: input data.\n",
        "    :param yvar: input labels.\n",
        "    :param predict: forward pass function.\n",
        "    :param nb_iter: number of iterations.\n",
        "    :param eps: maximum distortion.\n",
        "    :param eps_iter: attack step size.\n",
        "    :param loss_fn: loss function.\n",
        "    :param delta_init: (optional) tensor contains the random initialization.\n",
        "    :param minimize: (optional bool) whether to minimize or maximize the loss.\n",
        "    :param ord: (optional) the order of maximum distortion (inf or 2).\n",
        "    :param clip_min: mininum value per input dimension.\n",
        "    :param clip_max: maximum value per input dimension.\n",
        "    :param l1_sparsity: sparsity value for L1 projection.\n",
        "                  - if None, then perform regular L1 projection.\n",
        "                  - if float value, then perform sparse L1 descent from\n",
        "                    Algorithm 1 in https://arxiv.org/pdf/1904.13000v1.pdf\n",
        "    :return: tensor containing the perturbed input.\n",
        "    \"\"\"\n",
        "    #contain results\n",
        "    norm_memory=np.zeros((nb_iter,))\n",
        "    loss_memory=np.zeros((nb_iter,))\n",
        "    #\n",
        "\n",
        "    if delta_init is not None:\n",
        "        delta = delta_init\n",
        "    else:\n",
        "        delta = torch.zeros_like(embvar)\n",
        "\n",
        "    delta.requires_grad_()\n",
        "    for ii in range(nb_iter):\n",
        "        outputs = predict(xvar, embvar + delta)\n",
        "        loss = loss_fn(outputs, yvar)\n",
        "        if minimize:\n",
        "            loss = -loss \n",
        "\n",
        "        loss.backward()\n",
        "        if ord == np.inf:\n",
        "            grad_sign = delta.grad.data.sign()\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad_sign)\n",
        "            delta.data = batch_clamp(eps, delta.data)\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "\n",
        "        elif ord == 2:\n",
        "            grad = delta.grad.data\n",
        "            grad = normalize_by_pnorm(grad)\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad)\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "            if eps is not None:\n",
        "                delta.data = clamp_by_pnorm(delta.data, ord, eps)\n",
        "\n",
        "        elif ord == 1:\n",
        "            grad = delta.grad.data\n",
        "            abs_grad = torch.abs(grad)\n",
        "\n",
        "            batch_size = grad.size(0)\n",
        "            view = abs_grad.view(batch_size, -1)\n",
        "            view_size = view.size(1)\n",
        "            if l1_sparsity is None:\n",
        "                vals, idx = view.topk(1)\n",
        "            else:\n",
        "                vals, idx = view.topk(\n",
        "                    int(np.round((1 - l1_sparsity) * view_size)))\n",
        "\n",
        "            out = torch.zeros_like(view).scatter_(1, idx, vals)\n",
        "            out = out.view_as(grad)\n",
        "            grad = grad.sign() * (out > 0).float()\n",
        "            grad = normalize_by_pnorm(grad, p=1)\n",
        "            delta.data = delta.data + batch_multiply(eps_iter, grad)\n",
        "\n",
        "            delta.data = batch_l1_proj(delta.data.cpu(), eps)\n",
        "            if embvar.is_cuda:\n",
        "                delta.data = delta.data.cuda()\n",
        "            delta.data = clamp(embvar.data + delta.data, clip_min, clip_max\n",
        "                               ) - embvar.data\n",
        "        else:\n",
        "            error = \"Only ord = inf, ord = 1 and ord = 2 have been implemented\"\n",
        "            raise NotImplementedError(error)\n",
        "        delta.grad.data.zero_()\n",
        "\n",
        "        norm_memory[ii]=torch.norm(delta.data,2) \n",
        "        loss_memory[ii]= loss \n",
        "\n",
        "    emb_adv = clamp(embvar + delta, clip_min, clip_max)\n",
        "    return emb_adv, norm_memory, loss_memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ColIvU1LHy2W",
        "colab_type": "text"
      },
      "source": [
        "**gradient descent on one input WITH advertorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGz-F34ewAd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=input_ids[0].unsqueeze(0).to(device)\n",
        "emb=predict1(x)\n",
        "y=labels[0].unsqueeze(0).to(device)  \n",
        "att=PGDAttack(predict2, loss_fn=None, eps=0.3, nb_iter=100,\n",
        "            eps_iter=0.0001, rand_init=True, clip_min=0., clip_max=1.,\n",
        "            ord=np.inf, l1_sparsity=None, targeted=False)\n",
        "rval, norm_memory, loss_memory =att.perturb(x,emb,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v97xx_ZzGkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "608da324-446a-4ef2-abfc-7649b0243c8a"
      },
      "source": [
        "plt.plot(norm_memory)\n",
        "plt.suptitle('evolution of the norm of adversarial addition')\n",
        "plt.axis()\n",
        "plt.show()\n",
        "plt.plot(loss_memory)\n",
        "plt.suptitle('evolution of the losses')\n",
        "plt.show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEVCAYAAADwyx6sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU5dn/8c8FBMKSQAJhJwn74oJARNytS92o2tZWrQuolS6PrVqrj7Yura1tbfuzm09rVVRU3CqtWqvWuu9AQPZ9J2FJCNlJyHb9/pijjTFIIMvJzHzfr9e8mDnnnjnXmaPf3HOfzdwdERGJfh3CLkBERFqGAl1EJEYo0EVEYoQCXUQkRijQRURihAJdRCRGKNClRZhZppm5mXU6yPdfbGavtHRdTVjusWa21szKzOy8JrRv1no2+KyTzCynuZ8j8jEFurS5xkLR3We7+xdDKOcO4B537+HuzzacaWabzOzUEOoSOWAKdIl3GcDysIsQaQkK9DhkZgPNbI6Z5ZvZRjP7fr3pFWaWWq/tBDPbZWYJZtbBzG4xs81mlmdmj5hZz30s41M9WzP7iZk9Frx8O/i3KBjqONrMppvZu/XaH2Nm882sOPj3mHrz3jSzn5nZe2ZWamavmFmfz1nfq8xsnZntNrPnzWxgMH09MAz4Z1BHlwbvexRIrzf/xnqzLzazLcF38+N67+lgZjeZ2XozKzCzp+t/n5/HzMYG61ZkZsvN7Jx6884ysxXB+uaa2Q+D6X3M7IXgPbvN7B0z6xDMa3Q7B/Mmm1m2mZWY2U4zu7spNUo75+56xNGDyB/xBcBtQGcigbYBOD2Y/zpwVb32vwHuDZ5fAawL3tMD+DvwaDAvE3CgU/B6E3Bqvc/5CfBYY22DadOBd4PnqUAhcCnQCbgoeN07mP8msB4YBXQNXv9qH+t7MrALmAh0Af4EvF1v/qfqbOT9Ddfj49rvD5Y9HtgLjA3mXwN8CAwOlvdX4Il9fPZJQE7wPCH4bn8UbJeTgVJgdDB/O3B88DwFmBg8/yVwb/D+BOB4wJqwnT8ALg2e9wCmhP3fph7Nf6iHHn+OBNLc/Q53r3L3DUTC6cJg/uNEAhQzs2D648G8i4G73X2Du5cBNwMXtsQOwgbOBta6+6PuXuPuTwCrgC/Va/OQu69x9wrgaeCIfXzWxcCD7r7Q3fcGNR9tZpnNrPGn7l7h7ouBxUSCHeDbwI/dPSdY3k+A85vwHU0hEqy/CrbL68ALBNsCqAbGmVmyuxe6+8J60wcAGe5e7e7vuLuz/+1cDYwwsz7uXubuHzbz+5B2QIEefzKAgcFP9CIzKyLSK+wXzJ9DJPAGACcAdcA7wbyBwOZ6n7WZSA+6Hy2r4XI+Xtageq931Hu+h0gY7vezgj9EBQ0+62Dsa/kZwD/qfbcrgVr2/x0NBLa6e129afXX+avAWcBmM3vLzI4Opv+GSM/+FTPbYGY31avj87bzlUR+4awKhrSmNn3Vpb1q6Z6VtH9bgY3uPrKxme5eGBw+eAEwFngy6PEBbCMSFB9LB2qAnUSGGOorB7rVe92//mL2U2PD5Xy8rJf38779fpaZdQd6A7lNfP+BXo50K3CFu793gO/bBgwxsw71Qj0dWAPg7vOBc80sAbiayK+SIe5eClwPXG9mhwKvm9l89r+d1wIXBePtXwGeMbPe7l5+gHVLO6IeevyZB5Sa2f+aWVcz62hmh5rZkfXaPA5cBpzPf4dbAJ4ArjOzoWbWA/gF8JS71zSynEVEhmMSzCwr+KyP5RPp+Q/bR40vAqPM7Btm1snMLgDGERmCOFBPAJeb2RHBTs9fAHPdfVMT37/zc+pszL3AnWaWAWBmaWZ2bhPeN5dIT//G4Ds7icgQ05Nm1tkix+n3dPdqoITI94eZTTWzEcHwWDGRXwN17Gc7m9klZpYW/PEoCmqo/+tAopACPc64ey0wlciY80YiOwwfAOofrfI8MBLYEYwRf+xB4FEiR6lsBCqB7+1jUbcCw4nszPwp9f4wuPse4E7gvWA4YEqDGguCGq8nMjxyIzDV3XcdxPq+GtQyh8iOxeH8dxy5KX4J3BLU+cMmtP8Dke/vFTMrJbKD9Kgm1FlFJMDPJLJN/gxc5u6rgiaXApvMrITIOP3FwfSRwKtAGZEdnX929zeasJ3PAJabWVlQ84XB/giJYvbfX9MiIhLN1EMXEYkRCnQRkRihQBcRiREKdBGRGKFAFxGJEQp0EZEYoUAXEYkRCnQRkRihQBcRiREKdBGRGKFAFxGJEQp0EZEYoUAXEYkRCnQRkRihQBcRiREKdBGRGKFAFxGJEaHdJLpPnz6emZkZ1uJFRKLSggULdrl7WmPzQgv0zMxMsrOzw1q8iEhUMrPN+5qnIRcRkRihQBcRiREKdBGRGKFAFxGJEQp0EZEYoUAXEYkRCnQRkRgR2nHoIiLxoK7O2VhQTm5hBTtKKtlZXMkR6b04fmSj5wY1iwJdRKQFVFTVsj6/jG1FFWwvriS3qIKlOcUsyy2mdG/Np9p+56ThCnQRkbDtKtvLstxitu7eQ05hBZsL9rB6ZymbCspx/2+7zh07MGZAEudNGMRhg3uS2bs7/ZMT6ZvchcSEjq1SmwJdRKQRxRXVLN9WTG5hBTmFFWzYVc6irYVs3V3xSZvOHTswOLUro/slcc74gYzun8SQlG4M6JVIarfOdOhgbVqzAl1E4lpVTR1bdpezo3gv24srWLOzlA82FLB8W8knPW4zGNizK+OH9OTSKRkcPrgXQ/t0J61HlzYP7c+jQBeRuLC3ppZtRZXsKttLfuleVm0vYd6m3Xy0pYi9NXWftOvcsQMT0ntxzSkjmZSRQnpqNwb07ErnTu3/oEAFuojEnNo6Z1tRBZsKylm4uYgPNuxi4ZYiquoFdweDQwb25JIpGRw2qCcDeibSP3h06dQ6Y9ytTYEuIlGtrs7JLapg4ZZC5m3cTfamQjbsKqO6NjJeYgbjBiRz2ZQMxg5IJi2pC2lJXRic0pWkxISQq29ZCnQRiRp7a2pZvq2EBZsK+WhrIevzytlUUP7JkEmPLp2YmJHCF8b0JbN3N9J7d2PcgGR6desccuVtQ4EuIu3S7vIqPtpSyKKtRazLK2N9fhmbdu2hqjYS3kNSuzK6XzInjk4js3d3Dh/ck7EDkunYjnZStjUFuoiEbmdJJR9tKWT1jjLW7CxlxfYSNu4qByJj3Rm9uzM8rQcnj+nHEUN6MjE9hb7JiSFX3f4o0EWkTZVUVrN6Rykrt5ewJKeY+Zt2s7lgDxAZ705P7cbofkl8LWswk9JTOHxwL7p2js6dlG1NgS4iraayupZ1eWUsyy1mweZCFmwpZEN++SfzU7olkJWZyqVTMpiUkcLo/kl066xYOlj65kSkRdTVOWvySpm/cTfzNhWyLLeYzQXl1AUn56R278zE9BS+OnEw4wYkM2ZAEv2TEzGL3zHvlqZAF5EDVlvn5BZWsH5XGUtzIr3vj7YUUlIZuQhVv+QuTBiS8snp8GMHJJPZu5vCu5Up0EXkc7k76/LKyN5cyOKtRSzaWsSG/PJPjjYxg1F9kzj78IFMykhhcmYqQ1K7KrxD0ORAN7OOQDaQ6+5TG8ybDvwGyA0m3ePuD7RUkSLStqpr61iWW8wrK3by8rIdnxxx0rNrAuOH9OLEUWkMS+vOsLQejO6fRHKMnaATrQ6kh34NsBJI3sf8p9z96uaXJCJtrbbO+WhLIa+tyiN7026W5BSzt6aOjh2Mo4f15srjhnLciD5kaNikXWtSoJvZYOBs4E7gB61akYi0Ondnw65yFm6OnC7/+qo8Csqr6NTBOHRQTy4+KoOJGb04dngfUrrHx1mWsaCpPfTfAzcCSZ/T5qtmdgKwBrjO3bc2bGBmM4AZAOnp6QdYqog0R0llNW+vyefVFTt5e+0udpdXAZCc2IkTR/fli+P6ceLoNA2fRLH9BrqZTQXy3H2BmZ20j2b/BJ5w971m9i1gFnByw0bufh9wH0BWVpY3nC8iLad4TzVvr81n4ZZCFm4pYnluMTV1Tkq3BL4wui9HDUtlYnoKw9N6tKtresvBa0oP/VjgHDM7C0gEks3sMXe/5OMG7l5Qr/0DwK9btkwRaYqCsr28u24X/1y8jbfW5FNd6yQmdODwwb246oRhnDymLxPTU+L6eiexbL+B7u43AzcDBD30H9YP82D6AHffHrw8h8jOUxFpZRVVtby0bDuvr8pjcU7RJ7dH65+cyPRjMjnzsAEcNqgnCR3b/80ZpPkO+jh0M7sDyHb354Hvm9k5QA2wG5jeMuWJSEPFe6pZmlvMv5fv4NlFuZRW1tA/OZGJGb245KgMsjJTmDAkRcMoccjcwxnKzsrK8uzs7FCWLRJt1uWVMuv9zby9Nv+TC1l16dSBsw4bwNezhjBlWKoOJ4wTZrbA3bMam6czRUXaodo6Z+OucpblFjNnYQ7vrN1F544dOHF0Gl/PGsLhg3syfkgvHZEin6JAF2kn3J331hVw/zsbmLdxNxXVtQD0TerC9aeN4qKj0unTo0vIVUp7pkAXCVluUQUfrC/g4fc3siy3hL5JXbjgyCEcMjCZcQOTGdUvSTs1pUkU6CJtrK7O+WBDAXMW5vDh+gK2FVcCMLRPd371lcP48sRBUXvXeQmXAl2kjRRXVPPI+5t4KnsrOYUVJCd24vhRaVyVkUJWRirjBsb3/TCl+RToIq2sfG8ND7+/ib++tZ6SyhqOG9GHG04fzemH9CcxQT1xaTkKdJEWtGZnKc8tyuXN1fmU762hutYp2lNFeVUtp47tyw9OG824gfu6YKlI8yjQRVrAW2vy+dVLq1i5vYSOHYzJmamM6NuDhI4d6JrQkS9PHMTE9JSwy5QYp0AXaYayvTXc+a8VPDFvK8P6dOcnXxrH2YcPJC1JhxdK21OgixygvTW1LN5azNwNBTw5fyvbiyv41onDuO7UURoTl1Ap0EWaaG9NLb/7z1oefn8jldV1mMHhg3vxx4smMClDwykSPgW6SBOs3F7CdU8tYtWOUs47YiBnHTaAyUNT6dVNd/OR9kOBLrIP24oqeH99Ae+v28ULS7aT3DWBmdOyOGVsv7BLE2mUAl2kgfzSvdw0ZwmvrcoDILV7Z748YRD/e+YYUnV/TWnHFOgi9byxKo8bnllMSWUN1506itPG9WNM/yRdW1yiggJd4lpdnbMmr5QP1hfw3rpdvLoyj9H9kpj9zSmM7v9590QXaX8U6BK3thTs4TuzF7B8WwkAQ1K78u0Th3PtqSN1+KFEJQW6xKXXVu7kuqcWYWbc+eVDOWFkGkNSu4VdlkizKNAlrhSWV/HnN9dx/zsbOWRgMvdeMklBLjFDgS5xYXd5Ffe/s4FH3t9EeVUtF00ewu1fOkRDKxJTFOgSsyqra3ljVR7PLsrljVX5VNfVcfZhA/jeySO1w1NikgJdYs6eqhoe+WAzf31rPYV7qklL6sIlUzL4xlFDGNFXQS6xS4EuMaFsbw0rt5cwb+NuHnpvI7vKqjhxVBpXHjeUY4b3ppPuySlxQIEuUS2ncA/fenQBK7aX4B6ZduyI3vz1tFFMykgNtziRNtbkQDezjkA2kOvuUxvM6wI8AkwCCoAL3H1TC9Yp8hkVVbV869EFbCnYw3WnjuKQgckcMrAn/Xsmhl2aSCgOpId+DbASaOz+WVcChe4+wswuBO4CLmiB+kQa5e7c/PclrNhewsxpWZw8RhfMEmnSwKKZDQbOBh7YR5NzgVnB82eAU8xMF7+QVjPz3Y08u2gbP/ziaIW5SKCpPfTfAzcC+zpEYBCwFcDda8ysGOgN7Gp2hSLAhvwyfvPv1Wwq2MP24gqK9lRz1mH9+e5Jw8MuTaTd2G+gm9lUIM/dF5jZSc1ZmJnNAGYApKenN+ejJI6s3lHKxQ/Mpbq2jqyMFCZl9CKzd3e+cVQ6+iEo8l9N6aEfC5xjZmcBiUCymT3m7pfUa5MLDAFyzKwT0JPIztFPcff7gPsAsrKyvLnFS+xbllvMpTPn0rlTB56ccQwj+vYIuySRdmu/ge7uNwM3AwQ99B82CHOA54FpwAfA+cDr7q7AloNSW+cszinijVV5PPz+JpITE3j8qqPI6N097NJE2rWDPg7dzO4Ast39eWAm8KiZrQN2Axe2UH0SR9ydRz/czB9eXUtBeRUdOxhHDU3lN18bz6BeXcMuT6TdO6BAd/c3gTeD57fVm14JfK0lC5P4UlJZzU1zlvDi0h0cO6I3FxyZzokj0+jZLSHs0kSihs4UlVDV1jlvrs7jjhdWkFNYwc1njuGq44fplm8iB0GBLqHIK6nk6eytPDFvK7lFFQzq1ZWnZkwhK1On64scLAW6tJm6Oueddbt4Yu4WXl25k5o657gRfbjl7LGcOq4fCbqAlkizKNClTbg7Vz+xkBeX7iC1e2euPG4oF05OZ2gfHbki0lIU6NImHvtwMy8u3cH3TxnJ/3xhOF066U5BIi1NgS6tbvWOUn7+r5WcOCqNa08ZqR2eIq1Eg5bSqiqra/neEwtJSkzgt18brzAXaUXqoUurKK2s5vVVeTw5bytrdpYx64rJpCV1CbsskZimQJcWVVvn3PrcMp7JzqGqto6+SV24beo4ThyVFnZpIjFPgS4tpq4uctOJp7NzuGhyOudPGsSEISkaZhFpIwp0aRHuzs//tZKns3P4/ikj+cFpo8IuSSTuKNCl2Wpq6/jtK2t48L2NXHHsUK47dWTYJYnEJQW6NMuKbSX875wlLM0t5qLJ6dw6daxuOiESEgW6HJT80r088O4GZr6zkV7dEvjzxRM589D+CnORECnQ5YCs2VnK/W9v4LlF26iqreMrEwdx69njSOneOezSROKeAl2abO3OUqb+6V06mnHBkUO4/NhMhqXplnAi7YUCXZqkts753zlL6Na5I/++9gT6JSeGXZKINKBT/6VJHv1gEwu3FHHb1HEKc5F2SoEu+5VTuIdf/3s1J4xK48sTBoVdjojsgwJdPlddnfPjfywD4BdfPlRHsYi0Ywp02aea2jpunLOEt9bkc+Ppoxmc0i3skkTkc2inqDSqsrqWa578iH8v38l1p45i2jGZYZckIvuhQJfPqKyu5cpZ83lvXQG3f2kclx87NOySRKQJFOjyKXV1zvV/W8z76wv47dfGc/6kwWGXJCJNpDF0+ZTfv7aWfy3Zzk1njFGYi0SZ/Qa6mSWa2TwzW2xmy83sp420mW5m+Wa2KHh8s3XKldb03KJc/vjaWr6eNZgZJwwLuxwROUBNGXLZC5zs7mVmlgC8a2YvufuHDdo95e5Xt3yJ0hY+WF/ADc8s4aihqfz8vMN0eKJIFNpvoLu7A2XBy4Tg4a1ZlLSteRt3c8XD88ns3Y17L5lE504aiROJRk36P9fMOprZIiAP+I+7z22k2VfNbImZPWNmQ/bxOTPMLNvMsvPz85tRtrSUBZsLufyheQzslcjsb07RVRNFoliTAt3da939CGAwMNnMDm3Q5J9AprsfDvwHmLWPz7nP3bPcPSstTTcNDtuy3GKmPziPtKQuPH7VFNKSuoRdkog0wwH9tnb3IuAN4IwG0wvcfW/w8gFgUsuUJ61lc0E50x+aR3LXBB6/aoouuCUSA5pylEuamfUKnncFTgNWNWgzoN7Lc4CVLVmktKz80r1c9uA8auucWVdMZmCvrmGXJCItoClHuQwAZplZRyJ/AJ529xfM7A4g292fB75vZucANcBuYHprFSzNU7a3hisens/Okkoev2oKI/rqBhUiscIiB7G0vaysLM/Ozg5l2fGqbG8N0x+cx0dbi7j/skmcPKZf2CWJyAEyswXuntXYPJ36HydKK6uZ/tB8Fm0t4k8XTVCYi8QgBXocKKmsZtqD81iaU8w9F03gzMMG7P9NIhJ1FOgxbk9VDZc/ND8S5t+YyBmH9g+7JBFpJTolMIZVVtdy1SPZfLSlkD9eNEFhLhLj1EOPUVU1dXx39kLeW1fA3V8fz1kaZhGJeeqhx6C6OueGZxbz+qo8fn7eoXxloi6DKxIPFOgx6LevrOa5Rdu44fTRXDIlI+xyRKSNKNBjzOy5m/nzm+u5aHI63z1peNjliEgbUqDHkNdW7uTWZ5fxhdFp/OzcQ3RNc5E4o0CPEe+v28V3Zi/kkIE9uecbE+nUUZtWJN7o//oYsGDzbr75SDaZvbsx64rJdO+ig5dE4pECPcotyy1m+kPz6ZvUhce+eRSpukGFSNxSoEexHcWVXP7wfJITE5h91RT6Juma5iLxTIEepSqra5nxaDZ79tbw4PQjGaRrmovEPQ22RiF356Y5S1iSU8x9l05idP+ksEsSkXZAPfQodO9bG3h20TauP20UXzxE12cRkQgFepSZPXczd728iqmHD+Dqk0eEXY6ItCMK9CgyZ0EOtwQnDt399SN04pCIfIoCPUr8a8l2bnhmMccM781fLplE507adCLyaUqFKLBg826ue2oRE9NTuP+yLBITOoZdkoi0Qwr0di6ncA8zHlnAwF6J3H9ZFt0668AkEWmcAr0dK9tbwzdnZVNVW8cD044kRWeBisjnUHevnaqtc6598iPW5pXx8OVHMqJvj7BLEpF2Tj30duqul1fx6so8bv/SOI4fmRZ2OSISBfYb6GaWaGbzzGyxmS03s5820qaLmT1lZuvMbK6ZZbZGsfHiqflbuO/tDVx2dAaXHZ0ZdjkiEiWa0kPfC5zs7uOBI4AzzGxKgzZXAoXuPgL4HXBXy5YZPz5YX8CP/7GM40f24bap48IuR0SiyH4D3SPKgpcJwcMbNDsXmBU8fwY4xXTWywHbtKuc78xeQGaf7vzfxbpJhYgcmCYlhpl1NLNFQB7wH3ef26DJIGArgLvXAMVA70Y+Z4aZZZtZdn5+fvMqjzHFFdVcMWs+BsyclkVyYkLYJYlIlGlSoLt7rbsfAQwGJpvZoQezMHe/z92z3D0rLU07+j5WU1vH1Y8vZOvuPdx7ySQyencPuyQRiUIH9Jve3YuAN4AzGszKBYYAmFknoCdQ0BIFxoOf/2sl76zdxc/PO5Sjhn3mh42ISJM05SiXNDPrFTzvCpwGrGrQ7HlgWvD8fOB1d284zi6NeGZBDg+/v4krjxvKBUemh12OiESxppxYNACYZWYdifwBeNrdXzCzO4Bsd38emAk8ambrgN3Aha1WcQxZvq2YH/9jKUcP683NZ44JuxwRiXL7DXR3XwJMaGT6bfWeVwJfa9nSYlvxnmq+89hCenVL4E/fmKAjWkSk2XTqfwjq6pzr/7aIbUUVPPWtKfTp0SXskkQkBqhbGIKPT+u/5eyxTMpIDbscEYkRCvQ29uiHm/nr2xu4dEoG047JDLscEYkhCvQ29NrKndz+3DJOGdOX2780TreQE5EWpUBvIyu3l3D14x9xyMCe2gkqIq1CqdIGSiqr+c5jC0hK7MTMabrrkIi0DiVLK3N3bvzbErYWVvDkjCn0TU4MuyQRiVHqobeyme9u5OXlO7jpjDEcmakjWkSk9SjQW9H8Tbv55UurOOOQ/nzz+KFhlyMiMU6B3krySir57uyFpKd249dfO1xHtIhIq9MYeiuoqqnju7MXUlZZw2NXHqVrm4tIm1Cgt4JfvLiS7M2F/PGiCYzunxR2OSISJzTk0sKeW5TLw+9v4opjh3LO+IFhlyMicUSB3oJW7yjlpjlLOTIzhZvP0uVwRaRtKdBbSGlw8lCPxE783zcmkqAzQUWkjWkMvQW4Ozf8bQmbd+/hiat08pCIhEPdyBbw8clDN585hslDdfKQiIRDgd5My3KLuevlVZw2rh9XHqeTh0QkPAr0ZthTVcM1T35EavfO/PqrOnlIRMKlMfRm+NkLK9iwq5zZVx5FSvfOYZcjInFOPfSD9NLS7TwxbyvfPnE4x4zoE3Y5IiIK9IOxuaCcG59Zwvghvbju1FFhlyMiAijQD1hldS3fnb2QDh2Mey6aQOdO+gpFpH3QGPoB+tkLK1i+rYSZ07IYktot7HJERD6x3+6lmQ0xszfMbIWZLTezaxppc5KZFZvZouBxW+uUG67nF29j9twtfOuEYZwytl/Y5YiIfEpTeug1wPXuvtDMkoAFZvYfd1/RoN077j615UtsH/JKK7n12WVMSO/FD08fHXY5IiKfsd8eurtvd/eFwfNSYCUwqLULa29uf245FdW1/Ob88bpOi4i0SweUTGaWCUwA5jYy+2gzW2xmL5nZIS1QW7vx4tLtvLRsB9eeOpIRfXuEXY6ISKOavFPUzHoAc4Br3b2kweyFQIa7l5nZWcCzwMhGPmMGMAMgPT39oItuS4XlVdz23DIOG9STGccPC7scEZF9alIP3cwSiIT5bHf/e8P57l7i7mXB8xeBBDP7zNk27n6fu2e5e1ZaWlozS2997s6tzy2jaE81vz7/cDppqEVE2rGmHOViwExgpbvfvY82/YN2mNnk4HMLWrLQMPwtO4cXlmznutNGMXZActjliIh8rqYMuRwLXAosNbNFwbQfAekA7n4vcD7wHTOrASqAC93dW6HeNrMur5Tbn1/OMcN78+0Th4ddjojIfu030N39XeBzLyPo7vcA97RUUWGrrK7l6sc/olvnjvzugiPo2EFXURSR9k9nijbiVy+tYtWOUh66/Ej66e5DIhIltJevgQWbdzPrg01MPyaTL4zuG3Y5IiJNpkCvp6qmjpvmLGVgz67coLNBRSTKaMilnnvfWs/avDIemn4k3bvoqxGR6KIeemB9fhn3vL6OqYcP4AtjNNQiItFHgU7kBKKb/76UxIQO3P6lmLpqgYjEEQU68LcFOczbuJsfnTWWtKQuYZcjInJQ4j7Qd5dX8csXV3JkZgpfzxoSdjkiIgct7gP9zn+tpLSyhju/fBgddAKRiESxuA70D9YXMGdhDjNOGMaofklhlyMi0ixxG+hVNXXc8uxShqR25Xsnf+ZKvyIiUSduD7Z+5INNrM8vZ+a0LLp27hh2OSIizRaXPfRdZXv5w2trOXFUGifrmHMRiRFxGej/75XVVFTVcuvUcQSXcRcRiXpxF+jLcot5cv5Wph+TqfuDikhMiatAd3fu+OcKUrt15nunaEeoiMSWuAr0f3yUy7xNu7nh9NH07JoQdnSBCrEAAAdQSURBVDkiIi0qbgK9uKKaX7y4kgnpvXRGqIjEpLg5bPHuV1azu7yKhy+frDNCRSQmxUUPfVluMY9+uJlLp2Rw6KCeYZcjItIqYj7Q6+qcW55dRmr3zvzgi7oLkYjErpgP9Kezt7JoaxE3nzlWO0JFJKbFdKAXlldx18urODIzha9MHBR2OSIirSqmA/03r6ympLKGO849VGeEikjMi9lAX7y1iCfmbWHa0ZmMHZAcdjkiIq1uv4FuZkPM7A0zW2Fmy83smkbamJn90czWmdkSM5vYOuU2TW2dc9tzy+jTowvXnqYzQkUkPjTlOPQa4Hp3X2hmScACM/uPu6+o1+ZMYGTwOAr4S/BvKB6ft4XFOcX84cIjSE7UjlARiQ/77aG7+3Z3Xxg8LwVWAg33MJ4LPOIRHwK9zGxAi1fbBHmllfz65VUcO6I354wfGEYJIiKhOKAxdDPLBCYAcxvMGgRsrfc6h8+GPmY2w8yyzSw7Pz//wCptop+9sJK91XX8TDtCRSTONDnQzawHMAe41t1LDmZh7n6fu2e5e1ZaWtrBfMTnentNPv9cvI3vfmE4w9J0aVwRiS9NCnQzSyAS5rPd/e+NNMkF6l/xanAwrc1UVtdy63PLGNqnO98+cXhbLlpEpF1oylEuBswEVrr73fto9jxwWXC0yxSg2N23t2Cd+3XP6+vYXLCHn593KIkJukeoiMSfphzlcixwKbDUzBYF034EpAO4+73Ai8BZwDpgD3B5y5e6b6t3lHLvW+v5ysRBHDuiT1suWkSk3dhvoLv7u8Dn7l10dwf+p6WKOhB1dc6P/rGUpMRO3HL2uDBKEBFpF6L+TNHH521hweZCbjl7HKndO4ddjohIaKI60PNKKrnrpcgx57r4lojEu6gO9NufX05VbR13nneYjjkXkbgXtYH+yvIdvLRsB9ecOpLMPt3DLkdEJHRRGeilldXc9txyxvRP4qrjh4VdjohIuxCVN4n+7b9Xs7O0kr9cMpGEjlH5N0lEpMVFXRou3FLIIx9uZtrRmUxITwm7HBGRdiPqAr2jGceN6MMPT9cNn0VE6ou6IZfxQ3rx6JWhXWpdRKTdiroeuoiINE6BLiISIxToIiIxQoEuIhIjFOgiIjFCgS4iEiMU6CIiMUKBLiISIyxys6EQFmyWD2w+yLf3AXa1YDnRIh7XOx7XGeJzveNxneHA1zvD3dMamxFaoDeHmWW7e1bYdbS1eFzveFxniM/1jsd1hpZdbw25iIjECAW6iEiMiNZAvy/sAkISj+sdj+sM8bne8bjO0ILrHZVj6CIi8lnR2kMXEZEGoi7QzewMM1ttZuvM7Kaw62kNZjbEzN4wsxVmttzMrgmmp5rZf8xsbfBvTN6yycw6mtlHZvZC8Hqomc0NtvlTZtY57Bpbkpn1MrNnzGyVma00s6PjYVub2XXBf9/LzOwJM0uMxW1tZg+aWZ6ZLas3rdHtaxF/DNZ/iZlNPJBlRVWgm1lH4P+AM4FxwEVmNi7cqlpFDXC9u48DpgD/E6znTcBr7j4SeC14HYuuAVbWe30X8Dt3HwEUAleGUlXr+QPwsruPAcYTWfeY3tZmNgj4PpDl7ocCHYELic1t/TBwRoNp+9q+ZwIjg8cM4C8HsqCoCnRgMrDO3Te4exXwJHBuyDW1OHff7u4Lg+elRP4HH0RkXWcFzWYB54VTYesxs8HA2cADwWsDTgaeCZrE1HqbWU/gBGAmgLtXuXsRcbCtidwxrauZdQK6AduJwW3t7m8DuxtM3tf2PRd4xCM+BHqZ2YCmLivaAn0QsLXe65xgWswys0xgAjAX6Ofu24NZO4B+IZXVmn4P3AjUBa97A0XuXhO8jrVtPhTIBx4KhpkeMLPuxPi2dvdc4LfAFiJBXgwsILa3dX372r7NyrhoC/S4YmY9gDnAte5eUn+eRw5PiqlDlMxsKpDn7gvCrqUNdQImAn9x9wlAOQ2GV2J0W6cQ6Y0OBQYC3fnssERcaMntG22BngsMqfd6cDAt5phZApEwn+3ufw8m7/z451fwb15Y9bWSY4FzzGwTkeG0k4mML/cKfpZD7G3zHCDH3ecGr58hEvCxvq1PBTa6e767VwN/J7L9Y3lb17ev7dusjIu2QJ8PjAz2hHcmshPl+ZBranHBuPFMYKW7311v1vPAtOD5NOC5tq6tNbn7ze4+2N0ziWzb1939YuAN4PygWUytt7vvALaa2ehg0inACmJ8WxMZapliZt2C/94/Xu+Y3dYN7Gv7Pg9cFhztMgUorjc0s3/uHlUP4CxgDbAe+HHY9bTSOh5H5CfYEmBR8DiLyHjya8Ba4FUgNexaW/E7OAl4IXg+DJgHrAP+BnQJu74WXtcjgOxgez8LpMTDtgZ+CqwClgGPAl1icVsDTxDZT1BN5BfZlfvavoAROZJvPbCUyFFATV6WzhQVEYkR0TbkIiIi+6BAFxGJEQp0EZEYoUAXEYkRCnQRkRihQBcRiREKdBGRGKFAFxGJEf8fcy7FsWZh4skAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn1owLTzH-Kf",
        "colab_type": "text"
      },
      "source": [
        "**to be continued:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmM5Y-7DtyVL",
        "colab_type": "text"
      },
      "source": [
        "**gradient descent on batch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVTjjyQht1z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids_adv=input_ids.clone()\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset_adv = TensorDataset(input_ids_adv, labels)\n",
        " \n",
        "adv_size = len(dataset_adv)  \n",
        " \n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 10\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "dataloader_adv = DataLoader(\n",
        "            dataset_adv, # The validation samples.\n",
        "            sampler = SequentialSampler(dataset_adv), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-_ZPd-kt9oL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "10721e81-5012-4d8c-b745-0786f32927f4"
      },
      "source": [
        "#batch\n",
        "\n",
        "for batch in dataloader_adv:\n",
        "    \n",
        "  x = batch[0].to(device)\n",
        "\n",
        "  #descent param\n",
        "  lr = 1e-2\n",
        "  n_epochs = 10\n",
        "\n",
        "  add_memory=[]\n",
        "  addgrad_memory=[]\n",
        "  loss_memory=[]\n",
        "\n",
        "  #adversarial addition\n",
        "  add=torch.zeros([x.size()[0],64,768], dtype=torch.float, requires_grad=True).to(device)\n",
        "  for j in range(64):\n",
        "    for i in range(768):\n",
        "      add[0,j,i]+= 1.5e-04*random.random() #j'ajoute un delta aux embedding de tous les mots de chaque phrase\n",
        "\n",
        "  add.retain_grad()\n",
        "\n",
        "  #some model requirements for the calculation\n",
        "  padding_idx=1\n",
        "  input_shape = x.size()\n",
        "  seq_length = input_shape[1]\n",
        "  device = torch.device(\"cuda\") \n",
        "  position_ids = create_position_ids_from_input_ids(batch[0], 1).to(device) \n",
        "  token_type_ids=torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "  #model calculations:\n",
        "\n",
        "  emb=list(model.roberta.embeddings.children())[:1][0](x) #embedding of x\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    emb2=list(model.roberta.embeddings.children())[1:][0](position_ids)\n",
        "    emb3=list(model.roberta.embeddings.children())[1:][1](token_type_ids)\n",
        "    ess=list(model.roberta.embeddings.children())[1:][2](emb+add+emb2+emb3) #emb+add!\n",
        "    out_1st=list(model.roberta.embeddings.children())[1:][3](ess)  #result of the whole embedding layer of roberta\n",
        "\n",
        "    #getting result of encoder layer of roberta\n",
        "    out_2nd=model.roberta.encoder.layer[:12][0](out_1st)\n",
        "    for i in range(1,12):\n",
        "      out_2nd=model.roberta.encoder.layer[:12][i](out_2nd[0])\n",
        "\n",
        "    #getting result of pooler layer of roberta\n",
        "    out_3nd = model.roberta.pooler(out_2nd[0])\n",
        "    out_4nd=(out_2nd[0], out_3nd,) + out_2nd[1:]\n",
        "    out_fin=out_4nd[0]\n",
        "\n",
        "    #getting result of classifier layer of roberta\n",
        "    out=model.classifier(out_fin) #this is equivalent to model(x)\n",
        "\n",
        "    criterion=torch.nn.CrossEntropyLoss()\n",
        "    loss=criterion(out,batch[1].to(device)) \n",
        "    outgrad=loss.backward(retain_graph=True)\n",
        "\n",
        "    #just memorize experiment\n",
        "    add_memory+=[add]\n",
        "    addgrad_memory+=[add.grad] #check if not vanishing\n",
        "    loss_memory+=[loss]\n",
        "\n",
        "    with torch.no_grad():\n",
        "          add += lr * add.grad\n",
        "      \n",
        "    add.grad.zero_()\n",
        "\n",
        "\n",
        "  print('add norms:') #hopefully constant\n",
        "  print((float(torch.norm(add_memory[0],2)),float(torch.norm(add_memory[int(n_epochs/2)],2)),float(torch.norm(add_memory[-1],2))))\n",
        "  print('evolution of loss during epochs:') #hopefully increasing\n",
        "  print((float(loss_memory[0]),float(loss_memory[int(n_epochs/2)]),float(loss_memory[-1])))\n",
        "\n",
        "  for a in range(n_epochs):\n",
        "    add_memory[a]=float(torch.norm(add_memory[a],2))\n",
        "  plt.plot(add_memory)\n",
        "  plt.suptitle('evolution of the norm of adversarial addition')\n",
        "  plt.axis()\n",
        "  plt.show()\n",
        "  plt.plot(loss_memory)\n",
        "  plt.suptitle('evolution of the losses')\n",
        "  plt.show()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9f15430316c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0moutgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGwStDlFvUiy",
        "colab_type": "text"
      },
      "source": [
        "# loss of our model on adversarial dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49YvaHBZzPJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids_adv=input_ids.clone()\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset_adv = TensorDataset(input_ids_adv, labels) \n",
        " \n",
        "# Calculate the number of samples to include in each set.\n",
        "adv_size = int(0.015 * len(dataset))\n",
        "adv_size2 = len(dataset_adv) - adv_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "dataset_adv, dataset_adv2 = random_split(dataset, [adv_size, adv_size2])\n",
        " \n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 10\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "dataloader_adv = DataLoader(\n",
        "            dataset_adv, # The validation samples.\n",
        "            sampler = SequentialSampler(dataset_adv), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2TZkPrF3Db5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PREPARE ADVERSARIAL DATASET WITH GRADIENT DESCENT\n",
        "\n",
        "batch_size = 10\n",
        "add_data=[] #contains each adversarial addition for each batch\n",
        "\n",
        "for batch in dataloader_adv:\n",
        "    \n",
        "  x = batch[0].to(device)\n",
        "\n",
        "  #descent param\n",
        "  lr = 1e-2\n",
        "  n_epochs = 10\n",
        "\n",
        "  #adversarial addition\n",
        "  add=torch.zeros([x.size()[0],64,768], dtype=torch.float, requires_grad=True).to(device)\n",
        "  for j in range(64):\n",
        "    for i in range(768):\n",
        "      add[0,j,i]+= 1.5e-04*random.random() #j'ajoute un delta aux embedding de tous les mots de chaque phrase\n",
        "\n",
        "  add.retain_grad()\n",
        "\n",
        "  #some model requirements for the calculation\n",
        "  padding_idx=1\n",
        "  input_shape = x.size()\n",
        "  seq_length = input_shape[1]\n",
        "  device = torch.device(\"cuda\") \n",
        "  position_ids = create_position_ids_from_input_ids(batch[0], 1).to(device) \n",
        "  token_type_ids=torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "  #model calculations:\n",
        "\n",
        "  emb=list(model.roberta.embeddings.children())[:1][0](x) #embedding of x\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    emb2=list(model.roberta.embeddings.children())[1:][0](position_ids)\n",
        "    emb3=list(model.roberta.embeddings.children())[1:][1](token_type_ids)\n",
        "    ess=list(model.roberta.embeddings.children())[1:][2](emb+add+emb2+emb3) #emb+add!\n",
        "    out_1st=list(model.roberta.embeddings.children())[1:][3](ess)  #result of the whole embedding layer of roberta\n",
        "\n",
        "    #getting result of encoder layer of roberta\n",
        "    out_2nd=model.roberta.encoder.layer[:12][0](out_1st)\n",
        "    for i in range(1,12):\n",
        "      out_2nd=model.roberta.encoder.layer[:12][i](out_2nd[0])\n",
        "\n",
        "    #getting result of pooler layer of roberta\n",
        "    out_3nd = model.roberta.pooler(out_2nd[0])\n",
        "    out_4nd=(out_2nd[0], out_3nd,) + out_2nd[1:]\n",
        "    out_fin=out_4nd[0]\n",
        "\n",
        "    #getting result of classifier layer of roberta\n",
        "    out=model.classifier(out_fin) #this is equivalent to model(x)\n",
        "\n",
        "    criterion=torch.nn.CrossEntropyLoss()\n",
        "    loss=criterion(out,batch[1].to(device)) \n",
        "    outgrad=loss.backward(retain_graph=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "          add += lr * add.grad\n",
        "      \n",
        "    add.grad.zero_()\n",
        "\n",
        "\n",
        "  add_data+=[add]\n",
        "  if len(add_data)%10==0:\n",
        "    print(len(add_data))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-5aYT1oX4Jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(add_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80vT_WNUvZKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#COMPARE VALIDATION OF MODEL ON INITIAL DATASET AND ADVERSARIAL DATASET\n",
        " \n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "\n",
        "# ========================================\n",
        "#               Validation\n",
        "# ========================================\n",
        "# After the completion of each training epoch, measure our performance on\n",
        "# our validation set.\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables  \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "total_eval_accuracy_adv = 0\n",
        "total_eval_loss_adv = 0\n",
        "\n",
        "incr=0\n",
        "# Evaluate data for one epoch\n",
        "for batch in dataloader_adv:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[1].to(device)\n",
        "\n",
        "    b_input_ids_adv = batch[0].to(device)\n",
        "    b_labels_adv = batch[1].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        (loss, logits) = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                labels=b_labels)\n",
        "        \n",
        "        ################ beginning of loss calculation on adversarial dataset\n",
        "\n",
        "        #batch\n",
        "        x = b_input_ids_adv\n",
        "\n",
        "        #some model requirements for the calculation\n",
        "        padding_idx=1\n",
        "        input_shape = x.size()\n",
        "        seq_length = input_shape[1]\n",
        "        device = torch.device(\"cuda\") \n",
        "        position_ids = create_position_ids_from_input_ids(batch[0], 1).to(device) #b_input_ids_adv ?\n",
        "        token_type_ids=torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "        #model calculations:\n",
        "        emb=list(model.roberta.embeddings.children())[:1][0](x) #embedding of x\n",
        "        emb2=list(model.roberta.embeddings.children())[1:][0](position_ids)\n",
        "        emb3=list(model.roberta.embeddings.children())[1:][1](token_type_ids)\n",
        "        ess=list(model.roberta.embeddings.children())[1:][2](emb+add_data[incr]+emb2+emb3) #emb+add!\n",
        "        out_1st=list(model.roberta.embeddings.children())[1:][3](ess)  #result of the whole embedding layer of roberta\n",
        "\n",
        "        #getting result of encoder layer of roberta\n",
        "        out_2nd=model.roberta.encoder.layer[:12][0](out_1st)\n",
        "        for i in range(1,12):\n",
        "          out_2nd=model.roberta.encoder.layer[:12][i](out_2nd[0])\n",
        "\n",
        "        #getting result of pooler layer of roberta\n",
        "        out_3nd = model.roberta.pooler(out_2nd[0])\n",
        "        out_4nd=(out_2nd[0], out_3nd,) + out_2nd[1:]\n",
        "        out_fin=out_4nd[0]\n",
        "\n",
        "        #getting result of classifier layer of roberta\n",
        "        out=model.classifier(out_fin) #this is equivalent to model(x)\n",
        "\n",
        "        criterion=torch.nn.CrossEntropyLoss()\n",
        "        loss_adv=criterion(out,b_labels_adv) \n",
        "\n",
        "        logits_adv = out\n",
        "\n",
        "        ################ end of loss calculation on adversarial dataset\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "    total_eval_loss_adv += loss_adv.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    logits_adv = logits_adv.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    total_eval_accuracy_adv += flat_accuracy(logits_adv, label_ids)\n",
        "\n",
        "    incr+=1\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(dataloader_adv)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "avg_val_accuracy_adv = total_eval_accuracy_adv / len(dataloader_adv)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy_adv))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(dataloader_adv)\n",
        "avg_val_loss_adv = total_eval_loss_adv / len(dataloader_adv)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Validation took: {:}\".format(validation_time))\n",
        "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\" Valid. Accur.: {:}\".format(avg_val_accuracy))\n",
        "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss_adv))\n",
        "print(\" Valid. Accur.: {:}\".format(avg_val_accuracy_adv))\n",
        "\n",
        "print(\"\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}