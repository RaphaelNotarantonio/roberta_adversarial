{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "robertaclass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94f7b99217854ef88dffe880d1ebcfa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a884f9c1afe546df9e861f902f4838c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1c0159d699b400cbfb0631283a8f34d",
              "IPY_MODEL_d39f35e1f9224621a7f2e8dd1d4a370f"
            ]
          }
        },
        "a884f9c1afe546df9e861f902f4838c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1c0159d699b400cbfb0631283a8f34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a01198956c9749e18d960e7aed162d7d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7ff23bd047848179a071705de9c63e5"
          }
        },
        "d39f35e1f9224621a7f2e8dd1d4a370f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3655b5d09b04c008ad2b330313e34e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [07:16&lt;00:00, 1.10B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a2b0877e02c443fa377229251888314"
          }
        },
        "a01198956c9749e18d960e7aed162d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7ff23bd047848179a071705de9c63e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3655b5d09b04c008ad2b330313e34e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a2b0877e02c443fa377229251888314": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec4024ce96b04906928209e7675bb3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d83932b343e44cf97a66e1e6b502191",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0123efbdd0c24fadb31befe72b6a15cc",
              "IPY_MODEL_7f41698caf83476b874be76eef1b672c"
            ]
          }
        },
        "0d83932b343e44cf97a66e1e6b502191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0123efbdd0c24fadb31befe72b6a15cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a41cb0ef2d6346ad82e8c724f7fc2e1c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fba104d6564146008601dabe98f04398"
          }
        },
        "7f41698caf83476b874be76eef1b672c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3adc4a4f19e646029f738940e5c117d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:14&lt;00:00, 34.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2df1c7de072e47f69a771348219fa11d"
          }
        },
        "a41cb0ef2d6346ad82e8c724f7fc2e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fba104d6564146008601dabe98f04398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3adc4a4f19e646029f738940e5c117d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2df1c7de072e47f69a771348219fa11d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qznBxibXrK1-",
        "colab_type": "code",
        "outputId": "93ea1e40-fca2-4913-97dc-88265e3f1f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FnDd1XouFN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCdYD6i9wPiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RobertaClassificationHead(nn.Module):\n",
        "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "    def forward(self, features, **kwargs):\n",
        "        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense(x) \n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.out_proj(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANw1vGfUuDK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=torch.LongTensor([    0,  1541,   964,   351,    75,   907,    42,  1966,     6,   905,\n",
        "         1937,     5,   220,    65,    52, 15393,     4,     2,     1,     1,\n",
        "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
        "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
        "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
        "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
        "            1,     1,     1,     1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgAbTzmyslWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import RobertaForSequenceClassification, RobertaConfig, RobertaModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dry-zLxnzPIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers.modeling_utils import create_position_ids_from_input_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GinAujo42ocf",
        "colab_type": "text"
      },
      "source": [
        "model1: ok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-4jqLR_sbQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RobFirst(RobertaForSequenceClassification):\n",
        "\n",
        "  config_class = RobertaConfig \n",
        "  pretrained_model_archive_map = {\"roberta-base\": \"https://cdn.huggingface.co/roberta-base-pytorch_model.bin\"}\n",
        "  base_model_prefix = \"roberta\"\n",
        "  \n",
        "  def __init__(self,config):\n",
        "      super().__init__(config) \n",
        "\n",
        "  def forward(self, x):  #input -- x : input_id\n",
        "      return list(self.roberta.embeddings.children())[:1][0](x) #output: embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUGSQYmLt4VP",
        "colab_type": "code",
        "outputId": "71fb22a1-1fa0-41eb-b6eb-eeb08334100c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "94f7b99217854ef88dffe880d1ebcfa1",
            "a884f9c1afe546df9e861f902f4838c5",
            "a1c0159d699b400cbfb0631283a8f34d",
            "d39f35e1f9224621a7f2e8dd1d4a370f",
            "a01198956c9749e18d960e7aed162d7d",
            "f7ff23bd047848179a071705de9c63e5",
            "a3655b5d09b04c008ad2b330313e34e1",
            "9a2b0877e02c443fa377229251888314",
            "ec4024ce96b04906928209e7675bb3ea",
            "0d83932b343e44cf97a66e1e6b502191",
            "0123efbdd0c24fadb31befe72b6a15cc",
            "7f41698caf83476b874be76eef1b672c",
            "a41cb0ef2d6346ad82e8c724f7fc2e1c",
            "fba104d6564146008601dabe98f04398",
            "3adc4a4f19e646029f738940e5c117d5",
            "2df1c7de072e47f69a771348219fa11d"
          ]
        }
      },
      "source": [
        "model1 = RobFirst.from_pretrained(\"roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94f7b99217854ef88dffe880d1ebcfa1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec4024ce96b04906928209e7675bb3ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe4qg8BCvjGx",
        "colab_type": "code",
        "outputId": "a3c3f1d7-06c5-4d82-a392-6b3c045884d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "model1(x.unsqueeze(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1476, -0.0365,  0.0753,  ..., -0.0023,  0.0172, -0.0016],\n",
              "         [ 0.0136,  0.0257, -0.1996,  ...,  0.1035,  0.0316,  0.0828],\n",
              "         [-0.0049, -0.2004, -0.0588,  ..., -0.0298,  0.0075,  0.1229],\n",
              "         ...,\n",
              "         [ 0.0156,  0.0076, -0.0118,  ..., -0.0022,  0.0081, -0.0156],\n",
              "         [ 0.0156,  0.0076, -0.0118,  ..., -0.0022,  0.0081, -0.0156],\n",
              "         [ 0.0156,  0.0076, -0.0118,  ..., -0.0022,  0.0081, -0.0156]]],\n",
              "       grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09ZoI_pCx1OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb=model1(x.unsqueeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYpHUIVL2rCN",
        "colab_type": "text"
      },
      "source": [
        "model 2: pas ok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Ieh8SWwC3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RobSecond(RobertaForSequenceClassification):\n",
        "\n",
        "  config_class = RobertaConfig\n",
        "  pretrained_model_archive_map = {\"roberta-base\": \"https://cdn.huggingface.co/roberta-base-pytorch_model.bin\"}\n",
        "  base_model_prefix = \"roberta\"\n",
        "\n",
        "  def __init__(self, config):\n",
        "        super().__init__(config)  \n",
        "\n",
        "  def forward(self, x, emb): #inputs -- x : input_id  -- emb : embedding (RobFirst(x))\n",
        "    padding_idx=1\n",
        "    input_shape = x.size()\n",
        "    seq_length = input_shape[1]\n",
        "    #device cuda\n",
        "    position_ids = create_position_ids_from_input_ids(x, 1)\n",
        "    token_type_ids=torch.zeros(input_shape, dtype=torch.long) #, device=device\n",
        "\n",
        "    emb2=list(self.roberta.embeddings.children())[1:][0](position_ids)\n",
        "    emb3=list(self.roberta.embeddings.children())[1:][1](token_type_ids)\n",
        "    ess=list(self.roberta.embeddings.children())[1:][2](emb+emb2+emb3) \n",
        "    out_1st=list(self.roberta.embeddings.children())[1:][3](ess)  #result of the whole embedding layer of roberta\n",
        "\n",
        "    #getting result of encoder layer of roberta\n",
        "    out_2nd=self.roberta.encoder.layer[:12][0](out_1st)\n",
        "    for i in range(1,12):\n",
        "      out_2nd=self.roberta.encoder.layer[:12][i](out_2nd[0])\n",
        "\n",
        "    #getting result of pooler layer of roberta\n",
        "    out_3nd = self.roberta.pooler(out_2nd[0])\n",
        "    out_4nd=(out_2nd[0], out_3nd,) + out_2nd[1:]\n",
        "    out_fin=out_4nd[0]\n",
        "\n",
        "    #getting result of classifier layer of roberta\n",
        "    out=self.classifier(out_fin) #this is equivalent to model(x)\n",
        "\n",
        "    #criterion=torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    #loss=criterion(out,labels[0].unsqueeze(0))  #pas labels[0]\n",
        "\n",
        "    return out #this is equivalent to model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRrGcFbgwEg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = RobSecond.from_pretrained(\n",
        "    \"roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOgfTv8hxOT7",
        "colab_type": "code",
        "outputId": "4a79343d-7cc7-4c2c-bfb3-f76582b6c891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model2(x.unsqueeze(0),emb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0121,  0.2089]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsgzH_lQuRMN",
        "colab_type": "text"
      },
      "source": [
        "true model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7G1ImiduR1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        " \n",
        "# Tell pytorch to run this model on the GPU.\n",
        "#model.cuda()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTANaof3v1J9",
        "colab_type": "code",
        "outputId": "00558af6-e032-4a8b-b55c-b6010ec7f9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "model.roberta.embeddings.word_embeddings(x.unsqueeze(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1476, -0.0365,  0.0753,  ..., -0.0023,  0.0172, -0.0016],\n",
              "         [ 0.0136,  0.0257, -0.1996,  ...,  0.1035,  0.0316,  0.0828],\n",
              "         [-0.0049, -0.2004, -0.0588,  ..., -0.0298,  0.0075,  0.1229],\n",
              "         ...,\n",
              "         [ 0.0156,  0.0076, -0.0118,  ..., -0.0022,  0.0081, -0.0156],\n",
              "         [ 0.0156,  0.0076, -0.0118,  ..., -0.0022,  0.0081, -0.0156],\n",
              "         [ 0.0156,  0.0076, -0.0118,  ..., -0.0022,  0.0081, -0.0156]]],\n",
              "       grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVskYjyxxQTU",
        "colab_type": "code",
        "outputId": "2bca6b0b-b554-453d-f55a-56d6e9fc0d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model(x.unsqueeze(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0420, -0.0394]], grad_fn=<AddmmBackward>),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQUg8EBc03Eq",
        "colab_type": "text"
      },
      "source": [
        "dÃ©composÃ©: meme resultat que true model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCSFF_lD04Jc",
        "colab_type": "code",
        "outputId": "210e100b-adcc-4c20-d2ed-0c7ce134e0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y=x.unsqueeze(0)\n",
        "\n",
        "padding_idx=1\n",
        "input_shape = y.size()\n",
        "seq_length = input_shape[1]\n",
        "#device cuda\n",
        "position_ids = create_position_ids_from_input_ids(y, 1)\n",
        "token_type_ids=torch.zeros(input_shape, dtype=torch.long) #, device=device\n",
        "\n",
        "emb2=list(model.roberta.embeddings.children())[1:][0](position_ids)\n",
        "emb3=list(model.roberta.embeddings.children())[1:][1](token_type_ids)\n",
        "ess=list(model.roberta.embeddings.children())[1:][2](emb+emb2+emb3) \n",
        "out_1st=list(model.roberta.embeddings.children())[1:][3](ess)  #result of the whole embedding layer of roberta\n",
        "\n",
        "#getting result of encoder layer of roberta\n",
        "out_2nd=model.roberta.encoder.layer[:12][0](out_1st)\n",
        "for i in range(1,12):\n",
        "  out_2nd=model.roberta.encoder.layer[:12][i](out_2nd[0])\n",
        "\n",
        "#getting result of pooler layer of roberta\n",
        "out_3nd = model.roberta.pooler(out_2nd[0])\n",
        "out_4nd=(out_2nd[0], out_3nd,) + out_2nd[1:]\n",
        "out_fin=out_4nd[0]\n",
        "\n",
        "#getting result of classifier layer of roberta\n",
        "out=model.classifier(out_fin) #this is equivalent to model(x)\n",
        "\n",
        "#criterion=torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    #loss=criterion(out,labels[0].unsqueeze(0))  #pas labels[0]\n",
        "print(out) #this is equivalent to model(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0420, -0.0394]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}